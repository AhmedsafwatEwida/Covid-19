{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Ridge, RidgeCV\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":253,"outputs":[{"output_type":"stream","text":"/kaggle/input/countries-data/enriched_covid_19.csv\n/kaggle/input/covid19-global-forecasting-week-4/submission.csv\n/kaggle/input/covid19-global-forecasting-week-4/test.csv\n/kaggle/input/covid19-global-forecasting-week-4/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"counntries_df = pd.read_csv(\"/kaggle/input/countries-data/enriched_covid_19.csv\")","execution_count":254,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/submission.csv\")","execution_count":373,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Date'].max()","execution_count":374,"outputs":[{"output_type":"execute_result","execution_count":374,"data":{"text/plain":"'2020-05-06'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Date'].min()","execution_count":375,"outputs":[{"output_type":"execute_result","execution_count":375,"data":{"text/plain":"'2020-04-02'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()\n#train_df.info()","execution_count":257,"outputs":[{"output_type":"execute_result","execution_count":257,"data":{"text/plain":"                 Id  ConfirmedCases    Fatalities\ncount  33178.000000    33178.000000  33178.000000\nmean   17837.500000     2860.774218    186.124149\nstd    10300.654264    15961.579125   1538.811405\nmin        1.000000        0.000000      0.000000\n25%     8919.250000        0.000000      0.000000\n50%    17837.500000       12.000000      0.000000\n75%    26755.750000      375.750000      5.000000\nmax    35674.000000   323978.000000  30076.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ConfirmedCases</th>\n      <th>Fatalities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>33178.000000</td>\n      <td>33178.000000</td>\n      <td>33178.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>17837.500000</td>\n      <td>2860.774218</td>\n      <td>186.124149</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10300.654264</td>\n      <td>15961.579125</td>\n      <td>1538.811405</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8919.250000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>17837.500000</td>\n      <td>12.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>26755.750000</td>\n      <td>375.750000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>35674.000000</td>\n      <td>323978.000000</td>\n      <td>30076.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['ConfirmedCases']=train_df['ConfirmedCases'].replace([-1], 0)\ntrain_df['Fatalities']=train_df['Fatalities'].replace([-1], 0)","execution_count":258,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df['ConfirmedCases']==-1]","execution_count":259,"outputs":[{"output_type":"execute_result","execution_count":259,"data":{"text/plain":"Empty DataFrame\nColumns: [Id, Province_State, Country_Region, Date, ConfirmedCases, Fatalities]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>ConfirmedCases</th>\n      <th>Fatalities</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_df[\"key\"]=train_df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\ntest_df[\"key\"]=test_df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\n\n#test_new=pd.merge(test,train, how=\"left\", left_on=[\"key\",\"Date\"], right_on=[\"key\",\"Date\"] )\n#train.to_csv(directory + \"transfomed.csv\")\n\ntarget1=\"ConfirmedCases\"\ntarget2=\"Fatalities\"\nkey=\"key\"\ndef rate(frame, key, target, new_target_name=\"rate\"):\n   \n    corrections = 0\n    group_keys = frame[ key].values.tolist()\n    target = frame[target].values.tolist()\n    rate=[1.0 for k in range (len(target))]\n\n    for i in range(1, len(group_keys) - 1):\n        previous_group = group_keys[i - 1]\n        current_group = group_keys[i]\n\n        previous_value = target[i - 1]\n        current_value = target[i]\n         \n        if current_group == previous_group:\n                if previous_value!=0.0:\n                     rate[i]=current_value/previous_value\n\n                 \n        rate[i] =max(1,rate[i] )#correct negative values\n\n    frame[new_target_name] = np.array(rate)","execution_count":260,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"all_data_train_test=train_df.copy()","execution_count":261,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"all_data_train_test['mean_rate_case_last7']=0.00000000\nall_data_train_test['mean_rate_case_last3']=0.00000000\n\nall_data_train_test['mean_rate_case_last10']=0.00000000\nall_data_train_test['mean_rate_fat_last10']=0.00000000\n\nall_data_train_test['mean_rate_case_last5']=0.00000000\nall_data_train_test['mean_rate_fat_last5']=0.00000000\n\nall_data_train_test['mean_rate_case_last14']=0.00000000\nall_data_train_test['mean_rate_fat_last14']=0.00000000\n\nall_data_train_test['mean_rate_case_last20']=0.00000000\nall_data_train_test['mean_rate_fat_last20']=0.00000000\n\nall_data_train_test['mean_rate_case_each7']=0.00000000\nall_data_train_test['mean_rate_case_each3']=0.00000000\nall_data_train_test['mean_rate_case_each9']=0.00000000\nall_data_train_test['mean_rate_case_each10']=0.00000000\nall_data_train_test['mean_rate_case_each13']=0.00000000\n\nall_data_train_test['mean_rate_fat_last7']=0.00000000\nall_data_train_test['mean_rate_fat_last3']=0.00000000\nall_data_train_test['mean_rate_fat_each7']=0.00000000\nall_data_train_test['mean_rate_fat_each3']=0.00000000\nall_data_train_test['mean_rate_fat_each9']=0.00000000\nall_data_train_test['mean_rate_fat_each10']=0.00000000\nall_data_train_test['mean_rate_fat_each13']=0.00000000\n\nall_data_train_test['max_rate_case']=0.00000000\nall_data_train_test['min_rate_case']=0.00000000\nall_data_train_test['std_rate_case']=0.00000000\nall_data_train_test['mode_rate_case']=0.00000000\nall_data_train_test['range_rate_case']=0.00000000\nall_data_train_test['max_to_min_rate_case']=0.00000000\nall_data_train_test['max_rate_fat']=0.00000000\nall_data_train_test['min_rate_fat']=0.00000000\nall_data_train_test['std_rate_fat']=0.00000000\nall_data_train_test['mode_rate_fat']=0.00000000\nall_data_train_test['mean_rate_case']=0.00000000\nall_data_train_test['mean_rate_fat']=0.00000000\nall_data_train_test['range_rate_fat']=0.00000000       \nall_data_train_test['max_to_min_rate_fat']=0.00000000   \nall_data_train_test['cases_prev']=0  \nall_data_train_test['fat_prev']=0   \nall_data_train_test['mean_rate_fat_each10']=0.00000000","execution_count":262,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rate(all_data_train_test, key, target1, new_target_name=\"rate_\" +target1)\nrate(all_data_train_test, key, target2, new_target_name=\"rate_\" +target2)\nall_data_train_test.head()\nall_data_train_test.info()","execution_count":263,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 33178 entries, 0 to 33177\nData columns (total 47 columns):\nId                       33178 non-null int64\nProvince_State           14098 non-null object\nCountry_Region           33178 non-null object\nDate                     33178 non-null object\nConfirmedCases           33178 non-null float64\nFatalities               33178 non-null float64\nkey                      33178 non-null object\nmean_rate_case_last7     33178 non-null float64\nmean_rate_case_last3     33178 non-null float64\nmean_rate_case_last10    33178 non-null float64\nmean_rate_fat_last10     33178 non-null float64\nmean_rate_case_last5     33178 non-null float64\nmean_rate_fat_last5      33178 non-null float64\nmean_rate_case_last14    33178 non-null float64\nmean_rate_fat_last14     33178 non-null float64\nmean_rate_case_last20    33178 non-null float64\nmean_rate_fat_last20     33178 non-null float64\nmean_rate_case_each7     33178 non-null float64\nmean_rate_case_each3     33178 non-null float64\nmean_rate_case_each9     33178 non-null float64\nmean_rate_case_each10    33178 non-null float64\nmean_rate_case_each13    33178 non-null float64\nmean_rate_fat_last7      33178 non-null float64\nmean_rate_fat_last3      33178 non-null float64\nmean_rate_fat_each7      33178 non-null float64\nmean_rate_fat_each3      33178 non-null float64\nmean_rate_fat_each9      33178 non-null float64\nmean_rate_fat_each10     33178 non-null float64\nmean_rate_fat_each13     33178 non-null float64\nmax_rate_case            33178 non-null float64\nmin_rate_case            33178 non-null float64\nstd_rate_case            33178 non-null float64\nmode_rate_case           33178 non-null float64\nrange_rate_case          33178 non-null float64\nmax_to_min_rate_case     33178 non-null float64\nmax_rate_fat             33178 non-null float64\nmin_rate_fat             33178 non-null float64\nstd_rate_fat             33178 non-null float64\nmode_rate_fat            33178 non-null float64\nmean_rate_case           33178 non-null float64\nmean_rate_fat            33178 non-null float64\nrange_rate_fat           33178 non-null float64\nmax_to_min_rate_fat      33178 non-null float64\ncases_prev               33178 non-null int64\nfat_prev                 33178 non-null int64\nrate_ConfirmedCases      33178 non-null float64\nrate_Fatalities          33178 non-null float64\ndtypes: float64(40), int64(3), object(4)\nmemory usage: 11.9+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def mean_rate_each(df, country, col,tar):\n    target1=df[col][df['key']==country].values.tolist()\n    mean_rate_case_each7=[0 for k in range (len(target1))]\n    j=6\n    for i in range(1, len(target1) - 1):\n        if (i+j)<=(len(target1)):\n            \n            current_values1=[target1[i+j - 1],target1[i+j-2],target1[i+j -3],target1[i+j -4],target1[i+j -5],target1[i+j -6],target1[i+j -7]]\n           \n            mean_rate_case_each7[i+j-1]=np.mean(current_values1)\n        else:\n            break\n                                         \n    df[tar][df['key']==country]=np.array(mean_rate_case_each7)\ndef mean_rate_each3(df, country, col,tar):\n    target1=df[col][df['key']==country].values.tolist()\n    mean_rate_case_each3=[0 for k in range (len(target1))]\n    j=2\n    for i in range(1, len(target1) - 1):\n        if (i+j)<=(len(target1)):\n            \n            current_values1=[target1[i+j - 1],target1[i+j-2],target1[i+j -3]]\n           \n            mean_rate_case_each3[i+j-1]=np.mean(current_values1)\n        else:\n            break\n                                         \n    df[tar][df['key']==country]=np.array(mean_rate_case_each3)            \n    \ndef mean_rate_each10(df, country, col,tar):\n    target1=df[col][df['key']==country].values.tolist()\n    mean_rate_case_each10=[0 for k in range (len(target1))]\n    j=9\n    for i in range(1, len(target1) - 1):\n        if (i+j)<=(len(target1)):\n            \n            current_values1=[target1[i+j - 1],target1[i+j-2],target1[i+j -3],target1[i+j -4],target1[i+j -5],target1[i+j -6],target1[i+j -7],target1[i+j -8],target1[i+j -9],target1[i+j -10]]\n           \n            mean_rate_case_each10[i+j-1]=np.mean(current_values1)\n        else:\n            break\n                                         \n    df[tar][df['key']==country]=np.array(mean_rate_case_each10)  \ndef mean_rate_each13(df, country, col,tar):\n    target1=df[col][df['key']==country].values.tolist()\n    mean_rate_case_each13=[0 for k in range (len(target1))]\n    j=12\n    for i in range(1, len(target1) - 1):\n        if (i+j)<=(len(target1)):\n            \n            current_values1=[target1[i+j - 1],target1[i+j-2],target1[i+j -3],target1[i+j -4],target1[i+j -5],target1[i+j -6],target1[i+j -7],target1[i+j -8],target1[i+j -9],target1[i+j -10],target1[i+j -11],target1[i+j -12],target1[i+j -13]]\n           \n            mean_rate_case_each13[i+j-1]=np.mean(current_values1)\n        else:\n            break\n                                         \n    df[tar][df['key']==country]=np.array(mean_rate_case_each13)\n    \ndef mean_rate_each9(df, country, col,tar):\n    target1=df[col][df['key']==country].values.tolist()\n    mean_rate_case_each9=[0 for k in range (len(target1))]\n    j=8\n    for i in range(1, len(target1) - 1):\n        if (i+j)<=(len(target1)):\n            \n            current_values1=[target1[i+j - 1],target1[i+j-2],target1[i+j -3],target1[i+j -4],target1[i+j -5],target1[i+j -6],target1[i+j -7],target1[i+j -8],target1[i+j -9]]\n           \n            mean_rate_case_each9[i+j-1]=np.mean(current_values1)\n        else:\n            break\n                                         \n    df[tar][df['key']==country]=np.array(mean_rate_case_each9)","execution_count":264,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"group_keys = all_data_train_test['key'].values.tolist()\nfor coc in group_keys:\n    mean_rate_each(all_data_train_test, coc, col='rate_ConfirmedCases',tar='mean_rate_case_each7')\n    mean_rate_each(all_data_train_test, coc, col='rate_Fatalities',tar='mean_rate_fat_each7')\n    mean_rate_each3(all_data_train_test, coc, col='rate_ConfirmedCases',tar='mean_rate_case_each3')\n    mean_rate_each3(all_data_train_test, coc, col='rate_Fatalities',tar='mean_rate_fat_each3')\n    mean_rate_each13(all_data_train_test, coc, col='rate_ConfirmedCases',tar='mean_rate_case_each13')\n    mean_rate_each13(all_data_train_test, coc, col='rate_Fatalities',tar='mean_rate_fat_each13')\n    mean_rate_each9(all_data_train_test, coc, col='rate_ConfirmedCases',tar='mean_rate_case_each9')\n    mean_rate_each9(all_data_train_test, coc, col='rate_Fatalities',tar='mean_rate_fat_each9')\n    mean_rate_each10(all_data_train_test, coc, col='rate_ConfirmedCases',tar='mean_rate_case_each10')\n    mean_rate_each10(all_data_train_test, coc, col='rate_Fatalities',tar='mean_rate_fat_each10')\n    ","execution_count":265,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-265-ea9950370829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmean_rate_each13\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rate_Fatalities'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_rate_fat_each13'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmean_rate_each9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rate_ConfirmedCases'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_rate_case_each9'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmean_rate_each9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rate_Fatalities'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_rate_fat_each9'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmean_rate_each10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rate_ConfirmedCases'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_rate_case_each10'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmean_rate_each10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rate_Fatalities'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_rate_fat_each10'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-264-c296a06f1ae8>\u001b[0m in \u001b[0;36mmean_rate_each9\u001b[0;34m(df, country, col, tar)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_rate_case_each9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 raise TypeError(\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_keys = all_data_train_test['key'].values.tolist()\nfor coc in group_keys:\n    \n\n    all_data_train_test['mean_rate_case_each7']=all_data_train_test.rate_ConfirmedCases.rolling(7).mean() \n    all_data_train_test['mean_rate_case_each3']=all_data_train_test.rate_ConfirmedCases.rolling(3).mean() \n    all_data_train_test['mean_rate_case_each13']=all_data_train_test.rate_ConfirmedCases.rolling(13).mean() \n    all_data_train_test['mean_rate_case_each9']=all_data_train_test.rate_ConfirmedCases.rolling(9).mean() \n    all_data_train_test['mean_rate_case_each10']=all_data_train_test.rate_ConfirmedCases.rolling(10).mean() \n\n    all_data_train_test['mean_rate_fat_each7']=all_data_train_test.rate_Fatalities.rolling(7).mean() \n    all_data_train_test['mean_rate_fat_each3']=all_data_train_test.rate_Fatalities.rolling(3).mean() \n    all_data_train_test['mean_rate_fat_each13']=all_data_train_test.rate_Fatalities.rolling(13).mean() \n    all_data_train_test['mean_rate_fat_each9']=all_data_train_test.rate_Fatalities.rolling(9).mean() \n    all_data_train_test['mean_rate_fat_each10']=all_data_train_test.rate_Fatalities.rolling(10).mean() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_train_test[['mean_rate_case_each7','rate_ConfirmedCases']][all_data_train_test['Country_Region']=='Italy'].head(40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_train_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"all_data_train_test['Province_State'].fillna('NONE', inplace=True)\nall_data_train_test['ConfirmedCases'].fillna(0, inplace=True)\nall_data_train_test['Fatalities'].fillna(0, inplace=True)\nall_data_train_test['Id'].fillna(-1, inplace=True)\n#all_data_train_test['ForecastId'].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def infection_from_first_confirmed_cases(train_df,country):\n    \n    confirmed_cases = train_df[(train_df['Country_Region']==country_dict[country]) & train_df['ConfirmedCases']!=0].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n    fatalities_cases = train_df[(train_df['Country_Region']==country_dict[country]) & train_df['ConfirmedCases']!=0].groupby(['Date']).agg({'Fatalities':['sum']})\n    total_cases = confirmed_cases.join(fatalities_cases)\n    country_cases = [i for i in total_cases.ConfirmedCases['sum'].values]\n    country_cases_filter = country_cases[0:70] \n       \n    return country_cases_filter ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the mean foe last seven vlaues for fatalities and confirmed cases\ngroup_keys = all_data_train_test['key'].values.tolist()\nfor k in group_keys:\n    all_data_train_test['mean_rate_case_last7'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].tail(7).mean()\n    all_data_train_test['mean_rate_fat_last7'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k)&(all_data_train_test['Fatalities']!=0)].tail(7).mean()\n    all_data_train_test['mean_rate_case_last3'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].tail(3).mean()\n    all_data_train_test['mean_rate_fat_last3'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k)&(all_data_train_test['Fatalities']!=0)].tail(3).mean()\n    all_data_train_test['std_rate_case'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].std()\n    all_data_train_test['max_rate_case'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].max()\n    all_data_train_test['min_rate_case'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].min()\n    all_data_train_test['mode_rate_case'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].mode()\n    all_data_train_test['mean_rate_case'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].mean()\n    all_data_train_test['std_rate_fat'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k) & (all_data_train_test['Fatalities']!=0)].std()\n    all_data_train_test['max_rate_fat'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k) & (all_data_train_test['Fatalities']!=0)].max()\n    all_data_train_test['min_rate_fat'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k) & (all_data_train_test['Fatalities']!=0)].min()\n    all_data_train_test['mode_rate_fat'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k) & (all_data_train_test['Fatalities']!=0)].mode()\n    all_data_train_test['mean_rate_fat'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k) & (all_data_train_test['Fatalities']!=0)].mean()\n   \n    all_data_train_test['mean_rate_case_last10'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].tail(10).mean()\n    all_data_train_test['mean_rate_fat_last10'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k)&(all_data_train_test['Fatalities']!=0)].tail(10).mean()\n    all_data_train_test['mean_rate_case_last5'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].tail(5).mean()\n    all_data_train_test['mean_rate_fat_last5'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k)&(all_data_train_test['Fatalities']!=0)].tail(5).mean()\n\n    all_data_train_test['mean_rate_case_last14'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].tail(14).mean()\n    all_data_train_test['mean_rate_fat_last14'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k)&(all_data_train_test['Fatalities']!=0)].tail(14).mean()\n    all_data_train_test['mean_rate_case_last20'][all_data_train_test['key']==k]=all_data_train_test['rate_ConfirmedCases'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)].tail(20).mean()\n    all_data_train_test['mean_rate_fat_last20'][all_data_train_test['key']==k]=all_data_train_test['rate_Fatalities'][(all_data_train_test['key']==k)&(all_data_train_test['Fatalities']!=0)].tail(20).mean()\n    \n    \n    \n   # all_data_train_test['max_to_min_rate_case'][all_data_train_test['key']==k]=(all_data_train_test['max_rate_case'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)])/(all_data_train_test['min_rate_case'][(all_data_train_test['key']==k) & (all_data_train_test['ConfirmedCases']!=0)])\n    #all_data_train_test['max_to_min_rate_fat'][all_data_train_test['key']==k]=(all_data_train_test['max_rate_fat'][(all_data_train_test['key']==k) & (all_data_train_test['Fatalities']!=0)])/(all_data_train_test['min_rate_fat'][(all_data_train_test['key']==k) & (all_data_train_test['Fatalities']!=0)])\n    \n#all_data_train_test['cases_prev']=all_data_train_test['ConfirmedCases'].shift()\n#all_data_train_test['fat_prev']=all_data_train_test['Fatalities'].shift()                   \n\nall_data_train_test['max_to_min_rate_case']=all_data_train_test['max_rate_case']/all_data_train_test['min_rate_case']\nall_data_train_test['max_to_min_rate_fat']=all_data_train_test['max_rate_fat']/all_data_train_test['min_rate_fat']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_train_test['ConfirmedCases'][all_data_train_test['ConfirmedCases']==-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_train_test['cases_prev'] = all_data_train_test.groupby(\"key\")[\"ConfirmedCases\"].shift()\nall_data_train_test['fat_prev'] = all_data_train_test.groupby(\"key\")[\"Fatalities\"].shift()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for lag in range(1, ((train_df['Date'].max()-train_df['Date'].min()).days)):            \n    all_data_train_test[f\"lag_{lag}_cc\"] = all_data_train_test.groupby(\"key\")[\"ConfirmedCases\"].shift(lag)\n    all_data_train_test[f\"lag_{lag}_ft\"] = all_data_train_test.groupby(\"key\")[\"Fatalities\"].shift(lag)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_train_test[['mean_rate_case_last7','ConfirmedCases','rate_ConfirmedCases']][all_data_train_test['Country_Region']=='Qatar']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nall_data_train_test[all_data_train_test['Country_Region']=='Qatar'].tail(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"counntries_df.rename(columns={'Country/Region':'Country_Region','Province/State':'Province_State'},inplace = True)\ncounntries_df[\"key\"]=counntries_df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counntries_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"contries_data_columns=['Province_State', 'Country_Region', 'Lat', 'Long', 'Date',\n       'ConfirmedCases', 'Fatalities', 'age_0-4', 'age_5-9', 'age_10-14','key',\n       'age_15-19', 'age_20-24', 'age_25-29', 'age_30-34', 'age_35-39',\n       'age_40-44', 'age_45-49', 'age_50-54', 'age_55-59', 'age_60-64',\n       'age_65-69', 'age_70-74', 'age_75-79', 'age_80-84', 'age_85-89',\n       'age_90-94', 'age_95-99', 'age_100+', 'total_pop', 'smokers_perc',\n       'density', 'urbanpop', 'hospibed', 'lung', 'femalelung', 'malelung',\n       'restrictions', 'quarantine', 'schools']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"grouped_countries=counntries_df.groupby(['Country_Region'], as_index=False).agg({\"Lat\": \"max\",\"Long\": \"max\",'total_pop': \"max\",\n                                                                                         'smokers_perc': \"max\",'density': \"max\",'urbanpop': \"max\",\n                                                                                         'hospibed': \"max\",'lung': \"max\",'femalelung': \"max\",\n                                                                                         'malelung': \"max\",'restrictions': \"max\",'quarantine': \"max\",\n                                                                                         'schools': \"max\",'age_0-4': \"max\",'age_100+': \"max\",'age_5-9': \"max\",\n                                                                                         'age_95-99': \"max\",'age_90-94': \"max\",'age_85-89': \"max\",\n                                                                                         'age_80-84': \"max\",'age_75-79': \"max\",'age_70-74': \"max\",\n                                                                                         'age_65-69': \"max\",'age_60-64': \"max\",'age_55-59': \"max\",\n                                                                                         'age_50-54': \"max\",'age_45-49': \"max\",'age_40-44': \"max\",\n                                                                                         'age_35-39': \"max\",'age_30-34': \"max\",'age_25-29': \"max\",\n                                                                                         'age_20-24': \"max\",'age_15-19': \"max\",'age_10-14': \"max\",\n                                                                                         })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_countries=counntries_df.groupby(['key'], as_index=False).agg({\"Lat\": \"max\",\"Long\": \"max\",'total_pop': \"max\",\n                                                                                         'smokers_perc': \"max\",'density': \"max\",'urbanpop': \"max\",\n                                                                                         'hospibed': \"max\",'lung': \"max\",'femalelung': \"max\",\n                                                                                         'malelung': \"max\",'restrictions': \"max\",'quarantine': \"max\",\n                                                                                         'schools': \"max\",'age_0-4': \"max\",'age_100+': \"max\",'age_5-9': \"max\",\n                                                                                         'age_95-99': \"max\",'age_90-94': \"max\",'age_85-89': \"max\",\n                                                                                         'age_80-84': \"max\",'age_75-79': \"max\",'age_70-74': \"max\",\n                                                                                         'age_65-69': \"max\",'age_60-64': \"max\",'age_55-59': \"max\",\n                                                                                         'age_50-54': \"max\",'age_45-49': \"max\",'age_40-44': \"max\",\n                                                                                         'age_35-39': \"max\",'age_30-34': \"max\",'age_25-29': \"max\",\n                                                                                         'age_20-24': \"max\",'age_15-19': \"max\",'age_10-14': \"max\",\n                                                                                         })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"merged_train_df = pd.merge(all_data_train_test,\n                 grouped_countries[['Lat', 'Long',\n        'age_0-4', 'age_5-9', 'age_10-14','key',\n       'age_15-19', 'age_20-24', 'age_25-29', 'age_30-34', 'age_35-39',\n       'age_40-44', 'age_45-49', 'age_50-54', 'age_55-59', 'age_60-64',\n       'age_65-69', 'age_70-74', 'age_75-79', 'age_80-84', 'age_85-89',\n       'age_90-94', 'age_95-99', 'age_100+', 'total_pop', 'smokers_perc',\n       'density', 'urbanpop', 'hospibed', 'lung', 'femalelung', 'malelung',\n       'restrictions', 'quarantine', 'schools']],\n                 on='key',how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"merged_train_df['Date']= pd.to_datetime(merged_train_df['Date']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_train_df['confirmed_to_pop']=merged_train_df['ConfirmedCases']/(merged_train_df['total_pop']*1000)\nmerged_train_df['fat_to_pop']=merged_train_df['Fatalities']/(merged_train_df['total_pop']*1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_train_df[['confirmed_to_pop','ConfirmedCases','total_pop']][merged_train_df['Country_Region']=='Saudi Arabia']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_train_df[merged_train_df.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"merged_train_df['Province_State'].fillna('NONE', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"merged_train_df.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_c = merged_train_df['Country_Region']\ncountries = (merged_train_df['Country_Region'])\ncountry_dict = dict(zip(countries, number_c)) \ncountry_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"merged_train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"merged_train_df['Date_num'] = pd.to_datetime(merged_train_df['Date'])\nmerged_train_df['Date_num'] = merged_train_df['Date_num'].dt.strftime(\"%m%d\")\nmerged_train_df['Date_num']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"merged_test_df['Date_num'] = pd.to_datetime(merged_test_df['Date'])\nmerged_test_df['Date_num'] = merged_test_df['Date_num'].dt.strftime(\"%m%d\")\nmerged_test_df['Date_num']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"merged_train_df['Date_num']=merged_train_df['Date_num'].astype('int')\nmerged_test_df['Date_num']=merged_test_df['Date_num'].astype('int')\nmerged_train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combined"},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#'rate_ConfirmedCases','rate_Fatalities',\n\nfrom sklearn.preprocessing import MinMaxScaler\nmms = MinMaxScaler()\nmerged_train_df[['mean_rate_case_last7', 'mean_rate_case_last3',\n       'mean_rate_case_last10', 'mean_rate_fat_last10', 'mean_rate_case_last5',\n       'mean_rate_fat_last5', 'mean_rate_case_last14', 'mean_rate_fat_last14',\n       'mean_rate_case_last20', 'mean_rate_fat_last20', 'mean_rate_case_each7',\n       'mean_rate_case_each3', 'mean_rate_case_each9', 'mean_rate_case_each10',\n       'mean_rate_case_each13', 'mean_rate_fat_last7', 'mean_rate_fat_last3',\n       'mean_rate_fat_each7', 'mean_rate_fat_each3', 'mean_rate_fat_each9',\n        'mean_rate_fat_each13', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat',\n       'max_to_min_rate_fat', 'cases_prev', 'fat_prev', 'rate_ConfirmedCases',\n       'rate_Fatalities', 'mean_rate_fat_each10', 'age_0-4',\n       'age_5-9', 'age_10-14', 'age_15-19', 'age_20-24', 'age_25-29',\n       'age_30-34', 'age_35-39', 'age_40-44', 'age_45-49', 'age_50-54',\n       'age_55-59', 'age_60-64', 'age_65-69', 'age_70-74', 'age_75-79',\n       'age_80-84', 'age_85-89', 'age_90-94', 'age_95-99', 'age_100+',\n       'total_pop', 'smokers_perc', 'density', 'urbanpop', 'hospibed', 'lung',\n       'femalelung', 'malelung', 'restrictions', 'quarantine', 'schools']] = mms.fit_transform(merged_train_df[['mean_rate_case_last7', 'mean_rate_case_last3',\n       'mean_rate_case_last10', 'mean_rate_fat_last10', 'mean_rate_case_last5',\n       'mean_rate_fat_last5', 'mean_rate_case_last14', 'mean_rate_fat_last14',\n       'mean_rate_case_last20', 'mean_rate_fat_last20', 'mean_rate_case_each7',\n       'mean_rate_case_each3', 'mean_rate_case_each9', 'mean_rate_case_each10',\n       'mean_rate_case_each13', 'mean_rate_fat_last7', 'mean_rate_fat_last3',\n       'mean_rate_fat_each7', 'mean_rate_fat_each3', 'mean_rate_fat_each9',\n       'mean_rate_fat_each13', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat',\n       'max_to_min_rate_fat', 'cases_prev', 'fat_prev', 'rate_ConfirmedCases',\n       'rate_Fatalities', 'mean_rate_fat_each10', 'age_0-4',\n       'age_5-9', 'age_10-14', 'age_15-19', 'age_20-24', 'age_25-29',\n       'age_30-34', 'age_35-39', 'age_40-44', 'age_45-49', 'age_50-54',\n       'age_55-59', 'age_60-64', 'age_65-69', 'age_70-74', 'age_75-79',\n       'age_80-84', 'age_85-89', 'age_90-94', 'age_95-99', 'age_100+',\n       'total_pop', 'smokers_perc', 'density', 'urbanpop', 'hospibed', 'lung',\n       'femalelung', 'malelung', 'restrictions', 'quarantine', 'schools']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport xgboost as xgb\n\nfrom tensorflow.keras.optimizers import Nadam\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nimport tensorflow.keras.layers as KL\nfrom datetime import timedelta\nimport numpy as np\nimport pandas as pd\n\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression, Ridge\n\nimport datetime\nimport gc\nfrom tqdm import tqdm\ndef get_cpmp_sub(save_oof=False, save_public_test=False):\n    train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv')\n    train['Province_State'].fillna('', inplace=True)\n    train['Date'] = pd.to_datetime(train['Date'])\n    train['day'] = train.Date.dt.dayofyear\n    #train = train[train.day <= 85]\n    train['geo'] = ['_'.join(x) for x in zip(train['Country_Region'], train['Province_State'])]\n    train.fillna(0, inplace=True)\n    train['ConfirmedCases']=train['ConfirmedCases'].replace([-1], 0)\n    train['Fatalities']=train['Fatalities'].replace([-1], 0)\n    train\n\n    test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv')\n    test['Province_State'].fillna('', inplace=True)\n    test['Date'] = pd.to_datetime(test['Date'])\n    test['day'] = test.Date.dt.dayofyear\n    test['geo'] = ['_'.join(x) for x in zip(test['Country_Region'], test['Province_State'])]\n    test.fillna(0, inplace=True)\n    test\n\n    day_min = train['day'].min()\n    train['day'] -= day_min\n    test['day'] -= day_min\n\n    min_test_val_day = test.day.min()\n    max_test_val_day = train.day.max()\n    max_test_day = test.day.max()\n    num_days = max_test_day + 1\n\n    min_test_val_day, max_test_val_day, num_days\n\n    train['ForecastId'] = -1\n    test['Id'] = -1\n    test['ConfirmedCases'] = 0\n    test['Fatalities'] = 0\n\n    debug = False\n\n    data = pd.concat([train,\n                      test[test.day > max_test_val_day][train.columns]\n                     ]).reset_index(drop=True)\n    if debug:\n        data = data[data['geo'] >= 'France_'].reset_index(drop=True)\n    #del train, test\n    gc.collect()\n\n    dates = data[data['geo'] == 'France_'].Date.values\n\n    if 0:\n        gr = data.groupby('geo')\n        data['ConfirmedCases'] = gr.ConfirmedCases.transform('cummax')\n        data['Fatalities'] = gr.Fatalities.transform('cummax')\n\n    geo_data = data.pivot(index='geo', columns='day', values='ForecastId')\n    num_geo = geo_data.shape[0]\n    geo_data\n\n    geo_id = {}\n    for i,g in enumerate(geo_data.index):\n        geo_id[g] = i\n\n\n    ConfirmedCases = data.pivot(index='geo', columns='day', values='ConfirmedCases')\n    Fatalities = data.pivot(index='geo', columns='day', values='Fatalities')\n\n    if debug:\n        cases = ConfirmedCases.values\n        deaths = Fatalities.values\n    else:\n        cases = np.log1p(ConfirmedCases.values)\n        deaths = np.log1p(Fatalities.values)\n\n\n    def get_dataset(start_pred, num_train, lag_period): #63,5,14\n        days = np.arange( start_pred - num_train + 1, start_pred + 1)#(59,1,64)\n        lag_cases = np.vstack([cases[:, d - lag_period : d] for d in days])\n        lag_deaths = np.vstack([deaths[:, d - lag_period : d] for d in days])\n        target_cases = np.vstack([cases[:, d : d + 1] for d in days])\n        target_deaths = np.vstack([deaths[:, d : d + 1] for d in days])\n        geo_ids = np.vstack([geo_ids_base for d in days])\n        country_ids = np.vstack([country_ids_base for d in days])\n        return lag_cases, lag_deaths, target_cases, target_deaths, geo_ids, country_ids, days\n\n    def update_valid_dataset(data, pred_death, pred_case):\n        lag_cases, lag_deaths, target_cases, target_deaths, geo_ids, country_ids, days = data\n        day = days[-1] + 1\n        new_lag_cases = np.hstack([lag_cases[:, 1:], pred_case])\n        new_lag_deaths = np.hstack([lag_deaths[:, 1:], pred_death]) \n        new_target_cases = cases[:, day:day+1]\n        new_target_deaths = deaths[:, day:day+1] \n        new_geo_ids = geo_ids  \n        new_country_ids = country_ids  \n        new_days = 1 + days\n        return new_lag_cases, new_lag_deaths, new_target_cases, new_target_deaths, new_geo_ids, new_country_ids, new_days\n\n    def fit_eval(lr_death, lr_case, data, start_lag_death, end_lag_death, num_lag_case, fit, score):\n        lag_cases, lag_deaths, target_cases, target_deaths, geo_ids, country_ids, days = data\n\n        X_death = np.hstack([lag_cases[:, -start_lag_death:-end_lag_death], country_ids])\n        X_death = np.hstack([lag_deaths[:, -num_lag_case:], country_ids])\n        X_death = np.hstack([lag_cases[:, -start_lag_death:-end_lag_death], lag_deaths[:, -num_lag_case:], country_ids])\n        y_death = target_deaths\n        y_death_prev = lag_deaths[:, -1:]\n        if fit:\n            if 0:\n                keep = (y_death > 0).ravel()\n                X_death = X_death[keep]\n                y_death = y_death[keep]\n                y_death_prev = y_death_prev[keep]\n            lr_death.fit(X_death, y_death)\n        y_pred_death = lr_death.predict(X_death)\n        y_pred_death = np.maximum(y_pred_death, y_death_prev)\n\n        X_case = np.hstack([lag_cases[:, -num_lag_case:], geo_ids])\n        X_case = lag_cases[:, -num_lag_case:]\n        y_case = target_cases\n        y_case_prev = lag_cases[:, -1:]\n        if fit:\n            lr_case.fit(X_case, y_case)\n        y_pred_case = lr_case.predict(X_case)\n        y_pred_case = np.maximum(y_pred_case, y_case_prev)\n\n        if score:\n            death_score = val_score(y_death, y_pred_death)\n            case_score = val_score(y_case, y_pred_case)\n        else:\n            death_score = 0\n            case_score = 0\n\n        return death_score, case_score, y_pred_death, y_pred_case\n\n    def train_model(train, valid, start_lag_death, end_lag_death, num_lag_case, num_val, score=True):\n        alpha = 3\n        lr_death = Ridge(alpha=alpha, fit_intercept=False)\n        lr_case = Ridge(alpha=alpha, fit_intercept=True)\n\n        (train_death_score, train_case_score, train_pred_death, train_pred_case,\n        ) = fit_eval(lr_death, lr_case, train, start_lag_death, end_lag_death, num_lag_case, fit=True, score=score)\n\n        death_scores = []\n        case_scores = []\n\n        death_pred = []\n        case_pred = []\n\n        for i in range(num_val):\n\n            (valid_death_score, valid_case_score, valid_pred_death, valid_pred_case,\n            ) = fit_eval(lr_death, lr_case, valid, start_lag_death, end_lag_death, num_lag_case, fit=False, score=score)\n\n            death_scores.append(valid_death_score)\n            case_scores.append(valid_case_score)\n            death_pred.append(valid_pred_death)\n            case_pred.append(valid_pred_case)\n\n            if 0:\n                print('val death: %0.3f' %  valid_death_score,\n                      'val case: %0.3f' %  valid_case_score,\n                      'val : %0.3f' %  np.mean([valid_death_score, valid_case_score]),\n                      flush=True)\n            valid = update_valid_dataset(valid, valid_pred_death, valid_pred_case)\n\n        if score:\n            death_scores = np.sqrt(np.mean([s**2 for s in death_scores]))\n            case_scores = np.sqrt(np.mean([s**2 for s in case_scores]))\n            if 0:\n                print('train death: %0.3f' %  train_death_score,\n                      'train case: %0.3f' %  train_case_score,\n                      'val death: %0.3f' %  death_scores,\n                      'val case: %0.3f' %  case_scores,\n                      'val : %0.3f' % ( (death_scores + case_scores) / 2),\n                      flush=True)\n            else:\n                print('%0.4f' %  case_scores,\n                      ', %0.4f' %  death_scores,\n                      '= %0.4f' % ( (death_scores + case_scores) / 2),\n                      flush=True)\n        death_pred = np.hstack(death_pred)\n        case_pred = np.hstack(case_pred)\n        return death_scores, case_scores, death_pred, case_pred\n\n    countries = [g.split('_')[0] for g in geo_data.index]\n    countries = pd.factorize(countries)[0]\n\n    country_ids_base = countries.reshape((-1, 1))\n    ohe = OneHotEncoder(sparse=False)\n    country_ids_base = 0.2 * ohe.fit_transform(country_ids_base)\n    country_ids_base.shape\n\n    geo_ids_base = np.arange(num_geo).reshape((-1, 1))\n    ohe = OneHotEncoder(sparse=False)\n    geo_ids_base = 0.1 * ohe.fit_transform(geo_ids_base)\n    geo_ids_base.shape\n\n    def val_score(true, pred):\n        pred = np.log1p(np.round(np.expm1(pred) - 0.2))\n        return np.sqrt(mean_squared_error(true.ravel(), pred.ravel()))\n\n    def val_score(true, pred):\n        return np.sqrt(mean_squared_error(true.ravel(), pred.ravel()))\n\n#14,6,5,14\n\n    start_lag_death, end_lag_death = 14, 6,\n    num_train = 7\n    num_lag_case = 14\n    lag_period = max(start_lag_death, num_lag_case)  #14\n\n    def get_oof(start_val_delta=0):   \n        start_val = min_test_val_day + start_val_delta\n        last_train = start_val - 1\n        num_val = max_test_val_day - start_val + 1\n        print(dates[start_val], start_val, num_val)\n        train_data = get_dataset(last_train, num_train, lag_period)\n        valid_data = get_dataset(start_val, 1, lag_period)\n        _, _, val_death_preds, val_case_preds = train_model(train_data, valid_data, \n                                                            start_lag_death, end_lag_death, num_lag_case, num_val)\n\n        pred_deaths = Fatalities.iloc[:, start_val:start_val+num_val].copy()\n        pred_deaths.iloc[:, :] = np.expm1(val_death_preds)\n        pred_deaths = pred_deaths.stack().reset_index()\n        pred_deaths.columns = ['geo', 'day', 'Fatalities']\n        pred_deaths\n\n        pred_cases = ConfirmedCases.iloc[:, start_val:start_val+num_val].copy()\n        pred_cases.iloc[:, :] = np.expm1(val_case_preds)\n        pred_cases = pred_cases.stack().reset_index()\n        pred_cases.columns = ['geo', 'day', 'ConfirmedCases']\n        pred_cases\n\n        sub = train[['Date', 'Id', 'geo', 'day']]\n        sub = sub.merge(pred_cases, how='left', on=['geo', 'day'])\n        sub = sub.merge(pred_deaths, how='left', on=['geo', 'day'])\n        #sub = sub.fillna(0)\n        sub = sub[sub.day >= start_val]\n        sub = sub[['Id', 'ConfirmedCases', 'Fatalities']].copy()\n        return sub\n\n#'2020-03-27', '2020-03-24', '2020-03-21', '2020-03-18'\n#'2020-03-22', '2020-03-19', '2020-03-16', '2020-03-13'\n    if save_oof:\n        for start_val_delta, date in zip(range(3, -8, -3),\n                                  ['2020-03-22', '2020-03-19', '2020-03-16', '2020-03-13']):\n            print(date, end=' ')\n            oof = get_oof(start_val_delta)\n            oof.to_csv('../submissions/cpmp-%s.csv' % date, index=None)\n\n    def get_sub(start_val_delta=0):   \n        start_val = min_test_val_day + start_val_delta  #64\n        last_train = start_val - 1   #63\n        num_val = max_test_val_day - start_val + 1 #11\n        print(dates[last_train], start_val, num_val)\n        num_lag_case = 14  #14\n        train_data = get_dataset(last_train, num_train, lag_period)#63,5,14\n        valid_data = get_dataset(start_val, 1, lag_period) #64,1,14\n        _, _, val_death_preds, val_case_preds = train_model(train_data, valid_data, \n                                                            start_lag_death, end_lag_death, num_lag_case, num_val)\n\n        pred_deaths = Fatalities.iloc[:, start_val:start_val+num_val].copy()\n        pred_deaths.iloc[:, :] = np.expm1(val_death_preds)\n        pred_deaths = pred_deaths.stack().reset_index()\n        pred_deaths.columns = ['geo', 'day', 'Fatalities']\n        pred_deaths\n\n        pred_cases = ConfirmedCases.iloc[:, start_val:start_val+num_val].copy()\n        pred_cases.iloc[:, :] = np.expm1(val_case_preds)\n        pred_cases = pred_cases.stack().reset_index()\n        pred_cases.columns = ['geo', 'day', 'ConfirmedCases']\n        pred_cases\n\n        sub = test[['Date', 'ForecastId', 'geo', 'day']]\n        sub = sub.merge(pred_cases, how='left', on=['geo', 'day'])\n        sub = sub.merge(pred_deaths, how='left', on=['geo', 'day'])\n        sub = sub.fillna(0)\n        sub = sub[['ForecastId', 'ConfirmedCases', 'Fatalities']]\n        return sub\n        return sub\n\n\n    known_test = train[['geo', 'day', 'ConfirmedCases', 'Fatalities']\n              ].merge(test[['geo', 'day', 'ForecastId']], how='left', on=['geo', 'day'])\n    known_test = known_test[['ForecastId', 'ConfirmedCases', 'Fatalities']][known_test.ForecastId.notnull()].copy()\n    known_test\n\n    unknow_test = test[test.day > max_test_val_day]\n    unknow_test\n\n    def get_final_sub():   \n        start_val = max_test_val_day + 1\n        last_train = start_val - 1\n        num_val = max_test_day - start_val + 1\n        print(dates[last_train], start_val, num_val)\n        num_lag_case = num_val + 3\n        train_data = get_dataset(last_train, num_train, lag_period)\n        valid_data = get_dataset(start_val, 1, lag_period)\n        (_, _, val_death_preds, val_case_preds\n        ) = train_model(train_data, valid_data, start_lag_death, end_lag_death, num_lag_case, num_val, score=False)\n\n        pred_deaths = Fatalities.iloc[:, start_val:start_val+num_val].copy()\n        pred_deaths.iloc[:, :] = np.expm1(val_death_preds)\n        pred_deaths = pred_deaths.stack().reset_index()\n        pred_deaths.columns = ['geo', 'day', 'Fatalities']\n        pred_deaths\n\n        pred_cases = ConfirmedCases.iloc[:, start_val:start_val+num_val].copy()\n        pred_cases.iloc[:, :] = np.expm1(val_case_preds)\n        pred_cases = pred_cases.stack().reset_index()\n        pred_cases.columns = ['geo', 'day', 'ConfirmedCases']\n        pred_cases\n        print(unknow_test.shape, pred_deaths.shape, pred_cases.shape)\n\n        sub = unknow_test[['Date', 'ForecastId', 'geo', 'day']]\n        sub = sub.merge(pred_cases, how='left', on=['geo', 'day'])\n        sub = sub.merge(pred_deaths, how='left', on=['geo', 'day'])\n        #sub = sub.fillna(0)\n        sub = sub[['ForecastId', 'ConfirmedCases', 'Fatalities']]\n        sub = pd.concat([known_test, sub])\n        return sub\n\n    if save_public_test:\n        sub = get_sub()\n    else:\n        sub = get_final_sub()\n    return sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"merged_train_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"markdown","source":"# LGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime as dt, timedelta\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_score(y_true, y_pred):\n    y_true[y_true<0] = 0\n    score = metrics.mean_squared_error(np.log(y_true.clip(0, 1e10)+1), np.log(y_pred[:]+1))**0.5\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nparams = {'num_leaves': 8,\n          'min_data_in_leaf': 5,  # 42,\n          'objective': 'regression',\n          'max_depth': 8,\n          'learning_rate': 0.02,\n          'boosting': 'gbdt',\n          'bagging_freq': 5,  # 5\n          'bagging_fraction': 0.8,  # 0.5,\n          'feature_fraction': 0.8201,\n          'bagging_seed': SEED,\n          'reg_alpha': 1,  # 1.728910519108444,\n          'reg_lambda': 4.9847051755586085,\n          'random_state': SEED,\n          'metric': 'mse',\n          'verbosity': 100,\n          'min_gain_to_split': 0.02,  # 0.01077313523861969,\n          'min_child_weight': 5,  # 19.428902804238373,\n          'num_threads': 6,\n          }\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'mean_rate_case_last7', 'mean_rate_case_last3',\n       'mean_rate_case_last10', 'mean_rate_fat_last10', 'mean_rate_case_last5',\n       'mean_rate_fat_last5', 'mean_rate_case_last14', 'mean_rate_fat_last14',\n       'mean_rate_case_last20', 'mean_rate_fat_last20', 'mean_rate_case_each7',\n       'mean_rate_case_each3', 'mean_rate_case_each9', 'mean_rate_case_each10',\n       'mean_rate_case_each13', 'mean_rate_fat_last7', 'mean_rate_fat_last3',\n       'mean_rate_fat_each7', 'mean_rate_fat_each3', 'mean_rate_fat_each9',\n       'mean_rate_fat_each20', 'mean_rate_fat_each13', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat',\n       'max_to_min_rate_fat', 'cases_prev', 'fat_prev', 'rate_ConfirmedCases',\n       'rate_Fatalities', 'mean_rate_fat_each10', 'age_0-4',\n     \n       'total_pop', 'smokers_perc', 'density'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def get_nn_sub():\n    df = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")\n    df['ConfirmedCases']=df['ConfirmedCases'].replace([-1], 0)\n    df['Fatalities']=df['Fatalities'].replace([-1], 0)\n    sub_df = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\n    sub_df[\"key\"]=sub_df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\n    df[\"key\"]=df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\n    features_columns = ['Id', 'Province_State', 'Country_Region', 'Date', 'ConfirmedCases',\n       'Fatalities','mean_rate_case_last7', 'mean_rate_case_last3',\n       'mean_rate_case_last10', 'mean_rate_fat_last10', 'mean_rate_case_last5',\n       'mean_rate_fat_last5', 'mean_rate_case_last14', 'mean_rate_fat_last14',\n       'mean_rate_case_last20', 'mean_rate_fat_last20', 'mean_rate_case_each7',\n       'mean_rate_case_each3', 'mean_rate_case_each9', 'mean_rate_case_each10',\n       'mean_rate_case_each13', 'mean_rate_fat_last7', 'mean_rate_fat_last3',\n       'mean_rate_fat_each7', 'mean_rate_fat_each3', 'mean_rate_fat_each9',\n       'mean_rate_fat_each13', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat','Lat','Long',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat',\n       'max_to_min_rate_fat', 'cases_prev', 'fat_prev', 'rate_ConfirmedCases',\n       'rate_Fatalities', 'mean_rate_fat_each10',  'total_pop', 'smokers_perc', 'density']\n\n    '''coo_df = merged_train_df.groupby(\"Country_Region\")[['mean_rate_case_last7', 'mean_rate_case_each7',\n       'mean_rate_fat_last7', 'mean_rate_fat_each7', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat','cases_prev', 'fat_prev',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat','Lat','Long',\n       'max_to_min_rate_fat', 'rate_ConfirmedCases', 'rate_Fatalities','total_pop', 'smokers_perc', 'density']].mean().reset_index()'''\n    \n    coo_df = merged_train_df.groupby(\"Country_Region\")[['mean_rate_case_last7', 'mean_rate_case_last3',\n       'mean_rate_case_last10', 'mean_rate_fat_last10', 'mean_rate_case_last5',\n       'mean_rate_fat_last5', 'mean_rate_case_last14', 'mean_rate_fat_last14',\n       'mean_rate_case_last20', 'mean_rate_fat_last20', 'mean_rate_case_each7',\n       'mean_rate_case_each3', 'mean_rate_case_each9', 'mean_rate_case_each10',\n       'mean_rate_case_each13', 'mean_rate_fat_last7', 'mean_rate_fat_last3',\n       'mean_rate_fat_each7', 'mean_rate_fat_each3', 'mean_rate_fat_each9',\n      'mean_rate_fat_each13', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat','Lat','Long',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat',\n       'max_to_min_rate_fat', 'cases_prev', 'fat_prev', 'rate_ConfirmedCases',\n       'rate_Fatalities', 'mean_rate_fat_each10', 'total_pop', 'smokers_perc', 'density']].mean().reset_index()\n   # coo_df = coo_df[coo_df[\"Country_Region\"].notnull()]\n\n    loc_group = [\"Province_State\", \"Country_Region\"]\n    #loc_group = [\"key\"]\n   # merged_train_df['Date']= pd.to_datetime(merged_train_df['Date']) \n  #  merged_train_df[\"days\"] = (merged_train_df[\"Date\"] - pd.to_datetime(\"2020-01-01\")).dt.days\n\n    def preprocess(df):\n        df[\"Date\"] = df[\"Date\"].astype(\"datetime64[ms]\")\n  #  df[\"days\"] = (df[\"Date\"] - pd.to_datetime(\"2020-01-01\")).dt.days\n    #    df[\"weekend\"] = df[\"Date\"].dt.dayofweek//5\n\n        df = df.merge(coo_df, how=\"left\", on=\"Country_Region\")\n        #df = df.merge(coo_df, how=\"left\", on=\"key\")\n        df[\"Lat\"] = (df[\"Lat\"] // 30).astype(np.float32).fillna(0)\n        df[\"Long\"] = (df[\"Long\"] // 60).astype(np.float32).fillna(0)\n\n        for col in loc_group:\n            df[col].fillna(\"none\", inplace=True)\n        return df\n    merged_train_df2=pd.DataFrame(columns=features_columns)\n    merged_train_df2=merged_train_df[features_columns].copy()\n    #df = merged_train_df\n    df = preprocess(df)\n    sub_df = preprocess(sub_df)\n   # coo_df = coo_df[coo_df[\"Country_Region\"].notnull()]\n\n   # merged_train_df['Date']= pd.to_datetime(merged_train_df['Date']) \n  #  merged_train_df[\"days\"] = (merged_train_df[\"Date\"] - pd.to_datetime(\"2020-01-01\")).dt.days\n\n\n \n\n    print(df.shape)\n\n    TARGETS = [\"ConfirmedCases\", \"Fatalities\"]\n\n    for col in TARGETS:\n        df[col] = np.log1p(df[col])\n\n    NUM_SHIFT = 7\n#'1-smokers_perc','density'\n#2-'smokers_perc','density','mean_rate_case_last7'\n#3-'smokers_perc','density','mean_rate_case_last7','mean_rate_fat_last7'\n#4-'smokers_perc','density','mean_rate_fat_last7'\n#5-'mean_rate_case_last7','mean_rate_fat_last7'\n#6- Lat and Long\n#7-'mean_rate_case_last7', 'mean_rate_fat_last7','std_rate_case','std_rate_fat','density','Lat','Long'\n#8----'mean_rate_case_last7', 'mean_rate_fat_last7','std_rate_case', 'std_rate_fat','mean_rate_case', 'mean_rate_fat','rate_ConfirmedCases','rate_Fatalities'\n#9-'std_rate_case','std_rate_fat','mean_rate_case', 'mean_rate_fat','rate_ConfirmedCases','rate_Fatalities'\n#10--------'mean_rate_case_last7', 'mean_rate_case_each7',  'mean_rate_fat_last7', 'mean_rate_fat_each7',   'rate_ConfirmedCases', 'rate_Fatalities'\n#11    'mean_rate_case_last7', 'mean_rate_case_each7','std_rate_case','std_rate_fat', 'max_to_min_rate_case', 'max_to_min_rate_fat',       'mean_rate_fat_last7', 'mean_rate_fat_each7'\n#12-----'mean_rate_case_last7', 'mean_rate_case_each7','mean_rate_case_last3','mean_rate_fat_last3', 'max_to_min_rate_case','max_to_min_rate_fat', 'rate_ConfirmedCases', 'rate_Fatalities', 'mean_rate_case', 'mean_rate_fat','std_rate_fat','std_rate_case',              'mean_rate_fat_last7', 'mean_rate_fat_each7   \n    # we have to tune\n    \n    features = ['mean_rate_case_last7', 'mean_rate_case_last3',\n       'mean_rate_case_last10', 'mean_rate_fat_last10', 'mean_rate_case_last5',\n       'mean_rate_fat_last5', 'mean_rate_case_last14', 'mean_rate_fat_last14',\n       'mean_rate_case_last20', 'mean_rate_fat_last20', 'mean_rate_case_each7',\n       'mean_rate_case_each3', 'mean_rate_case_each9', 'mean_rate_case_each10',\n       'mean_rate_case_each13', 'mean_rate_fat_last7', 'mean_rate_fat_last3',\n       'mean_rate_fat_each7', 'mean_rate_fat_each3', 'mean_rate_fat_each9',\n       'mean_rate_fat_each13', \n      'rate_ConfirmedCases',\n       'rate_Fatalities', 'mean_rate_fat_each10']\n  \n\n    for s in range(1, NUM_SHIFT+1):\n        for col in TARGETS:\n            df[\"prev_{}_{}\".format(col, s)] = df.groupby(loc_group)[col].shift(s)\n            features.append(\"prev_{}_{}\".format(col, s))\n\n    df = df[df[\"Date\"] >= df[\"Date\"].min() + timedelta(days=NUM_SHIFT)].copy()\n\n    TEST_FIRST = sub_df[\"Date\"].min() # pd.to_datetime(\"2020-03-13\") #\n    TEST_DAYS = (df[\"Date\"].max() - TEST_FIRST).days + 1\n\n    dev_df, test_df = df[df[\"Date\"] < TEST_FIRST].copy(), df[df[\"Date\"] >= TEST_FIRST].copy()\n\n    def nn_block(input_layer, size, dropout_rate, activation):\n        out_layer = KL.Dense(size, activation=None)(input_layer)\n        #out_layer = KL.BatchNormalization()(out_layer)\n        out_layer = KL.Activation(activation)(out_layer)\n        out_layer = KL.Dropout(dropout_rate)(out_layer)\n        return out_layer\n    '''def get_model():\n        inp = KL.Input(shape=(len(features),))\n\n        hidden_layer = nn_block(inp, 256,0, \"relu\")\n        hidden_layer = nn_block(hidden_layer,128, 0.0, \"relu\")\n        gate_layer = nn_block(hidden_layer,64, 0.0, \"sigmoid\")\n        hidden_layer = nn_block(hidden_layer,128, 0, \"relu\")\n        hidden_layer = nn_block(hidden_layer,64, 0.1, \"relu\") #0.05\n        hidden_layer = KL.multiply([hidden_layer, gate_layer])\n\n        out = KL.Dense(len(TARGETS), activation=\"linear\")(hidden_layer)\n\n        model = tf.keras.models.Model(inputs=[inp], outputs=out)\n        return model'''\n    '''def get_model():\n        inp = KL.Input(shape=(len(features),))\n\n        hidden_layer = nn_block(inp, 128,0, \"relu\")\n        hidden_layer = nn_block(hidden_layer,64, 0.0, \"relu\")\n        gate_layer = nn_block(hidden_layer,32, 0.0, \"sigmoid\")\n\n        hidden_layer = nn_block(hidden_layer,32, 0.2, \"relu\") #0.05\n        hidden_layer = KL.multiply([hidden_layer, gate_layer])\n\n        out = KL.Dense(len(TARGETS), activation=\"linear\")(hidden_layer)\n\n        model = tf.keras.models.Model(inputs=[inp], outputs=out)\n        return model'''\n\n\n    def get_model():\n        inp = KL.Input(shape=(len(features),))\n\n        hidden_layer = nn_block(inp, 64, 0.0, \"relu\")\n        gate_layer = nn_block(hidden_layer, 32, 0.0, \"sigmoid\")\n        hidden_layer = nn_block(hidden_layer, 32, 0, \"relu\")\n       # hidden_layer = nn_block(hidden_layer, 64, 0, \"relu\")\n        hidden_layer = KL.multiply([hidden_layer, gate_layer])\n\n        out = KL.Dense(len(TARGETS), activation=\"linear\")(hidden_layer)\n\n        model = tf.keras.models.Model(inputs=[inp], outputs=out)\n        return model\n    '''def get_model():\n        inp = KL.Input(shape=(len(features),))\n\n        hidden_layer = nn_block(inp, 64, 0.0, \"relu\")#64\n        gate_layer = nn_block(hidden_layer, 32, 0.0, \"sigmoid\")#32\n        hidden_layer = nn_block(hidden_layer, 32, 0, \"relu\")\n        hidden_layer = KL.multiply([hidden_layer, gate_layer])\n\n        out = KL.Dense(len(TARGETS), activation=\"linear\")(hidden_layer)\n\n        model = tf.keras.models.Model(inputs=[inp], outputs=out)\n        return model'''\n\n    get_model().summary()\n\n    def get_input(df):\n        return [df[features]]\n\n    NUM_MODELS = 10\n\n\n    def train_models(df, save=False):\n        models = []\n        for i in range(NUM_MODELS):\n            model = get_model()\n            model.compile(loss=\"mean_squared_error\", optimizer=Nadam(lr=1e-4))\n            hist = model.fit(get_input(df), df[TARGETS],\n                             batch_size=2048, epochs=500, verbose=0, shuffle=True)\n            if save:\n                model.save_weights(\"model{}.h5\".format(i))\n            models.append(model)\n        return models\n\n    models = train_models(dev_df)\n\n\n    prev_targets = ['prev_ConfirmedCases_1', 'prev_Fatalities_1']\n\n    def predict_one(df, models):\n        pred = np.zeros((df.shape[0], 2))\n        for model in models:\n            pred += model.predict(get_input(df))/len(models)\n        pred = np.maximum(pred, df[prev_targets].values)\n        pred[:, 0] = np.log1p(np.expm1(pred[:, 0]) + 0.1)\n        pred[:, 1] = np.log1p(np.expm1(pred[:, 1]) + 0.01)\n        return np.clip(pred, None, 15)\n\n    print([mean_squared_error(dev_df[TARGETS[i]], predict_one(dev_df, models)[:, i]) for i in range(len(TARGETS))])\n\n\n    def rmse(y_true, y_pred):\n        return np.sqrt(mean_squared_error(y_true, y_pred))\n\n    def evaluate(df):\n        error = 0\n        for col in TARGETS:\n            error += rmse(df[col].values, df[\"pred_{}\".format(col)].values)\n        return np.round(error/len(TARGETS), 5)\n\n\n    def predict(test_df, first_day, num_days, models, val=False):\n        temp_df = test_df.loc[test_df[\"Date\"] == first_day].copy()\n        y_pred = predict_one(temp_df, models)\n\n        for i, col in enumerate(TARGETS):\n            test_df[\"pred_{}\".format(col)] = 0\n            test_df.loc[test_df[\"Date\"] == first_day, \"pred_{}\".format(col)] = y_pred[:, i]\n\n        print(first_day, np.isnan(y_pred).sum(), y_pred.min(), y_pred.max())\n        if val:\n            print(evaluate(test_df[test_df[\"Date\"] == first_day]))\n\n\n        y_prevs = [None]*NUM_SHIFT\n\n        for i in range(1, NUM_SHIFT):\n            y_prevs[i] = temp_df[['prev_ConfirmedCases_{}'.format(i), 'prev_Fatalities_{}'.format(i)]].values\n\n        for d in range(1, num_days):\n            date = first_day + timedelta(days=d)\n            print(date, np.isnan(y_pred).sum(), y_pred.min(), y_pred.max())\n\n            temp_df = test_df.loc[test_df[\"Date\"] == date].copy()\n            temp_df[prev_targets] = y_pred\n            for i in range(2, NUM_SHIFT+1):\n                temp_df[['prev_ConfirmedCases_{}'.format(i), 'prev_Fatalities_{}'.format(i)]] = y_prevs[i-1]\n\n            y_pred, y_prevs = predict_one(temp_df, models), [None, y_pred] + y_prevs[1:-1]\n\n\n            for i, col in enumerate(TARGETS):\n                test_df.loc[test_df[\"Date\"] == date, \"pred_{}\".format(col)] = y_pred[:, i]\n\n            if val:\n                print(evaluate(test_df[test_df[\"Date\"] == date]))\n\n        return test_df\n\n    test_df = predict(test_df, TEST_FIRST, TEST_DAYS, models, val=True)\n    print(evaluate(test_df))\n\n    for col in TARGETS:\n        test_df[col] = np.expm1(test_df[col])\n        test_df[\"pred_{}\".format(col)] = np.expm1(test_df[\"pred_{}\".format(col)])\n\n    models = train_models(df, save=True)\n\n    sub_df_public = sub_df[sub_df[\"Date\"] <= df[\"Date\"].max()].copy()\n    sub_df_private = sub_df[sub_df[\"Date\"] > df[\"Date\"].max()].copy()\n\n    pred_cols = [\"pred_{}\".format(col) for col in TARGETS]\n    #sub_df_public = sub_df_public.merge(test_df[[\"Date\"] + loc_group + pred_cols].rename(columns={col: col[5:] for col in pred_cols}), \n    #                                    how=\"left\", on=[\"Date\"] + loc_group)\n    sub_df_public = sub_df_public.merge(test_df[[\"Date\"] + loc_group + TARGETS], how=\"left\", on=[\"Date\"] + loc_group)\n\n    SUB_FIRST = sub_df_private[\"Date\"].min()\n    SUB_DAYS = (sub_df_private[\"Date\"].max() - sub_df_private[\"Date\"].min()).days + 1\n\n    sub_df_private = df.append(sub_df_private, sort=False)\n\n    for s in range(1, NUM_SHIFT+1):\n        for col in TARGETS:\n            sub_df_private[\"prev_{}_{}\".format(col, s)] = sub_df_private.groupby(loc_group)[col].shift(s)\n\n    sub_df_private = sub_df_private[sub_df_private[\"Date\"] >= SUB_FIRST].copy()\n\n    sub_df_private = predict(sub_df_private, SUB_FIRST, SUB_DAYS, models)\n\n    for col in TARGETS:\n        sub_df_private[col] = np.expm1(sub_df_private[\"pred_{}\".format(col)])\n\n    sub_df = sub_df_public.append(sub_df_private, sort=False)\n    sub_df[\"ForecastId\"] = sub_df[\"ForecastId\"].astype(np.int16)\n\n    return sub_df[[\"ForecastId\"] + TARGETS]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1 = get_cpmp_sub()\nsub1['ForecastId'] = sub1['ForecastId'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"sub2 = get_nn_sub()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"sub1.sort_values(\"ForecastId\", inplace=True)\nsub2.sort_values(\"ForecastId\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nTARGETS = [\"ConfirmedCases\", \"Fatalities\"]\n\n[np.sqrt(mean_squared_error(np.log1p(sub1[t].values), np.log1p(sub2[t].values))) for t in TARGETS]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"sub_df = sub1.copy()\nfor t in TARGETS:\n    sub_df[t] = np.expm1(np.log1p(sub1[t].values)*0.00+ np.log1p(sub2[t].values)*1).astype('int')\n    \nsub_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"Predicted_data = pd.merge(df_sub ,\n                 test_df[['ForecastId','Province_State','Country_Region','Date']],\n                 on='ForecastId',how='left')","execution_count":370,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"target1=\"ConfirmedCases\"\ntarget2=\"Fatalities\"\nkey=\"Country_Region\"\ndef trend(frame, key, target, new_target_name=\"trend\"):\n   \n    corrections = 0\n    group_keys = frame[ key].values.tolist()\n    target = frame[target].values.tolist()\n    trend=[1.0 for k in range (len(target))]\n\n    for i in range(1, len(group_keys) - 1):\n        previous_group = group_keys[i - 1]\n        current_group = group_keys[i]\n\n        previous_value = target[i - 1]\n        current_value = target[i]\n         \n        if current_group == previous_group:\n                if previous_value!=0.0:\n                     trend[i]=current_value-previous_value\n\n                 \n        trend[i] =max(1,trend[i] )#correct negative values\n\n    frame[new_target_name] = np.array(trend)\ntrend(Predicted_data, key, target1, new_target_name=\"trend_\" +target1)\ntrend(Predicted_data, key, target2, new_target_name=\"trend_\" +target2)    ","execution_count":371,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"Predicted_data[Predicted_data['Country_Region']=='Qatar']\n","execution_count":372,"outputs":[{"output_type":"execute_result","execution_count":372,"data":{"text/plain":"      ForecastId  ConfirmedCases  Fatalities Province_State Country_Region  \\\n8686        8687      949.000000    3.000000            NaN          Qatar   \n8687        8688     1075.000000    3.000000            NaN          Qatar   \n8688        8689     1325.000000    3.000000            NaN          Qatar   \n8689        8690     1604.000000    4.000000            NaN          Qatar   \n8690        8691     1832.000000    4.000000            NaN          Qatar   \n8691        8692     2057.000000    6.000000            NaN          Qatar   \n8692        8693     2210.000000    6.000000            NaN          Qatar   \n8693        8694     2376.000000    6.000000            NaN          Qatar   \n8694        8695     2512.000000    6.000000            NaN          Qatar   \n8695        8696     2728.000000    6.000000            NaN          Qatar   \n8696        8697     2979.000000    7.000000            NaN          Qatar   \n8697        8698     3231.000000    7.000000            NaN          Qatar   \n8698        8699     3428.000000    7.000000            NaN          Qatar   \n8699        8700     3711.000000    7.000000            NaN          Qatar   \n8700        8701     4103.000000    7.000000            NaN          Qatar   \n8701        8702     4663.000000    7.000000            NaN          Qatar   \n8702        8703     5008.000000    8.000000            NaN          Qatar   \n8703        8704     5448.000000    8.000000            NaN          Qatar   \n8704        8705     6015.000000    9.000000            NaN          Qatar   \n8705        8706     6533.000000    9.000000            NaN          Qatar   \n8706        8707     7141.000000   10.000000            NaN          Qatar   \n8707        8708     7764.000000   10.000000            NaN          Qatar   \n8708        8709     8525.000000   10.000000            NaN          Qatar   \n8709        8710     9358.000000   10.000000            NaN          Qatar   \n8710        8711    10287.000000   10.000000            NaN          Qatar   \n8711        8712    11244.000000   10.000000            NaN          Qatar   \n8712        8713    11921.000000   10.000000            NaN          Qatar   \n8713        8714    12564.000000   10.000000            NaN          Qatar   \n8714        8715    12564.484763   10.022005            NaN          Qatar   \n8715        8716    12564.971650   10.044010            NaN          Qatar   \n8716        8717    12565.458537   10.066016            NaN          Qatar   \n8717        8718    12565.945424   10.088021            NaN          Qatar   \n8718        8719    12566.432310   10.110026            NaN          Qatar   \n8719        8720    12566.919197   10.132031            NaN          Qatar   \n8720        8721    12567.406084   10.154037            NaN          Qatar   \n8721        8722    12567.892971   10.176042            NaN          Qatar   \n8722        8723    12568.379858   10.198047            NaN          Qatar   \n8723        8724    12568.866745   10.220052            NaN          Qatar   \n8724        8725    12569.353632   10.242058            NaN          Qatar   \n8725        8726    12569.840519   10.264063            NaN          Qatar   \n8726        8727    12570.321765   10.286068            NaN          Qatar   \n8727        8728    12570.760122   10.308073            NaN          Qatar   \n8728        8729    12571.198479   10.330078            NaN          Qatar   \n\n            Date  trend_ConfirmedCases  trend_Fatalities  \n8686  2020-04-02                   1.0               1.0  \n8687  2020-04-03                 126.0               1.0  \n8688  2020-04-04                 250.0               1.0  \n8689  2020-04-05                 279.0               1.0  \n8690  2020-04-06                 228.0               1.0  \n8691  2020-04-07                 225.0               2.0  \n8692  2020-04-08                 153.0               1.0  \n8693  2020-04-09                 166.0               1.0  \n8694  2020-04-10                 136.0               1.0  \n8695  2020-04-11                 216.0               1.0  \n8696  2020-04-12                 251.0               1.0  \n8697  2020-04-13                 252.0               1.0  \n8698  2020-04-14                 197.0               1.0  \n8699  2020-04-15                 283.0               1.0  \n8700  2020-04-16                 392.0               1.0  \n8701  2020-04-17                 560.0               1.0  \n8702  2020-04-18                 345.0               1.0  \n8703  2020-04-19                 440.0               1.0  \n8704  2020-04-20                 567.0               1.0  \n8705  2020-04-21                 518.0               1.0  \n8706  2020-04-22                 608.0               1.0  \n8707  2020-04-23                 623.0               1.0  \n8708  2020-04-24                 761.0               1.0  \n8709  2020-04-25                 833.0               1.0  \n8710  2020-04-26                 929.0               1.0  \n8711  2020-04-27                 957.0               1.0  \n8712  2020-04-28                 677.0               1.0  \n8713  2020-04-29                 643.0               1.0  \n8714  2020-04-30                   1.0               1.0  \n8715  2020-05-01                   1.0               1.0  \n8716  2020-05-02                   1.0               1.0  \n8717  2020-05-03                   1.0               1.0  \n8718  2020-05-04                   1.0               1.0  \n8719  2020-05-05                   1.0               1.0  \n8720  2020-05-06                   1.0               1.0  \n8721  2020-05-07                   1.0               1.0  \n8722  2020-05-08                   1.0               1.0  \n8723  2020-05-09                   1.0               1.0  \n8724  2020-05-10                   1.0               1.0  \n8725  2020-05-11                   1.0               1.0  \n8726  2020-05-12                   1.0               1.0  \n8727  2020-05-13                   1.0               1.0  \n8728  2020-05-14                   1.0               1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ForecastId</th>\n      <th>ConfirmedCases</th>\n      <th>Fatalities</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>trend_ConfirmedCases</th>\n      <th>trend_Fatalities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8686</th>\n      <td>8687</td>\n      <td>949.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-02</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8687</th>\n      <td>8688</td>\n      <td>1075.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-03</td>\n      <td>126.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8688</th>\n      <td>8689</td>\n      <td>1325.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-04</td>\n      <td>250.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8689</th>\n      <td>8690</td>\n      <td>1604.000000</td>\n      <td>4.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-05</td>\n      <td>279.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8690</th>\n      <td>8691</td>\n      <td>1832.000000</td>\n      <td>4.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-06</td>\n      <td>228.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8691</th>\n      <td>8692</td>\n      <td>2057.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-07</td>\n      <td>225.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>8692</th>\n      <td>8693</td>\n      <td>2210.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-08</td>\n      <td>153.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8693</th>\n      <td>8694</td>\n      <td>2376.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-09</td>\n      <td>166.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8694</th>\n      <td>8695</td>\n      <td>2512.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-10</td>\n      <td>136.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8695</th>\n      <td>8696</td>\n      <td>2728.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-11</td>\n      <td>216.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8696</th>\n      <td>8697</td>\n      <td>2979.000000</td>\n      <td>7.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-12</td>\n      <td>251.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8697</th>\n      <td>8698</td>\n      <td>3231.000000</td>\n      <td>7.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-13</td>\n      <td>252.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8698</th>\n      <td>8699</td>\n      <td>3428.000000</td>\n      <td>7.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-14</td>\n      <td>197.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8699</th>\n      <td>8700</td>\n      <td>3711.000000</td>\n      <td>7.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-15</td>\n      <td>283.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8700</th>\n      <td>8701</td>\n      <td>4103.000000</td>\n      <td>7.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-16</td>\n      <td>392.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8701</th>\n      <td>8702</td>\n      <td>4663.000000</td>\n      <td>7.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-17</td>\n      <td>560.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8702</th>\n      <td>8703</td>\n      <td>5008.000000</td>\n      <td>8.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-18</td>\n      <td>345.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8703</th>\n      <td>8704</td>\n      <td>5448.000000</td>\n      <td>8.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-19</td>\n      <td>440.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8704</th>\n      <td>8705</td>\n      <td>6015.000000</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-20</td>\n      <td>567.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8705</th>\n      <td>8706</td>\n      <td>6533.000000</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-21</td>\n      <td>518.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8706</th>\n      <td>8707</td>\n      <td>7141.000000</td>\n      <td>10.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-22</td>\n      <td>608.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8707</th>\n      <td>8708</td>\n      <td>7764.000000</td>\n      <td>10.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-23</td>\n      <td>623.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8708</th>\n      <td>8709</td>\n      <td>8525.000000</td>\n      <td>10.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-24</td>\n      <td>761.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8709</th>\n      <td>8710</td>\n      <td>9358.000000</td>\n      <td>10.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-25</td>\n      <td>833.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8710</th>\n      <td>8711</td>\n      <td>10287.000000</td>\n      <td>10.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-26</td>\n      <td>929.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8711</th>\n      <td>8712</td>\n      <td>11244.000000</td>\n      <td>10.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-27</td>\n      <td>957.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8712</th>\n      <td>8713</td>\n      <td>11921.000000</td>\n      <td>10.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-28</td>\n      <td>677.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8713</th>\n      <td>8714</td>\n      <td>12564.000000</td>\n      <td>10.000000</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-29</td>\n      <td>643.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8714</th>\n      <td>8715</td>\n      <td>12564.484763</td>\n      <td>10.022005</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-04-30</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8715</th>\n      <td>8716</td>\n      <td>12564.971650</td>\n      <td>10.044010</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-01</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8716</th>\n      <td>8717</td>\n      <td>12565.458537</td>\n      <td>10.066016</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-02</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8717</th>\n      <td>8718</td>\n      <td>12565.945424</td>\n      <td>10.088021</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-03</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8718</th>\n      <td>8719</td>\n      <td>12566.432310</td>\n      <td>10.110026</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-04</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8719</th>\n      <td>8720</td>\n      <td>12566.919197</td>\n      <td>10.132031</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-05</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8720</th>\n      <td>8721</td>\n      <td>12567.406084</td>\n      <td>10.154037</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-06</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8721</th>\n      <td>8722</td>\n      <td>12567.892971</td>\n      <td>10.176042</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-07</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8722</th>\n      <td>8723</td>\n      <td>12568.379858</td>\n      <td>10.198047</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-08</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8723</th>\n      <td>8724</td>\n      <td>12568.866745</td>\n      <td>10.220052</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-09</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8724</th>\n      <td>8725</td>\n      <td>12569.353632</td>\n      <td>10.242058</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-10</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8725</th>\n      <td>8726</td>\n      <td>12569.840519</td>\n      <td>10.264063</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-11</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8726</th>\n      <td>8727</td>\n      <td>12570.321765</td>\n      <td>10.286068</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-12</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8727</th>\n      <td>8728</td>\n      <td>12570.760122</td>\n      <td>10.308073</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-13</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8728</th>\n      <td>8729</td>\n      <td>12571.198479</td>\n      <td>10.330078</td>\n      <td>NaN</td>\n      <td>Qatar</td>\n      <td>2020-05-14</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"confirmed_total_date = Predicted_data.groupby(['Date']).agg({'trend_ConfirmedCases':'sum','ConfirmedCases':'sum'})\nfatalities_total_date = Predicted_data.groupby(['Date']).agg({'trend_Fatalities':'sum','Fatalities':'sum'})\nprint(confirmed_total_date)\nprint(fatalities_total_date)","execution_count":288,"outputs":[{"output_type":"stream","text":"            trend_ConfirmedCases  ConfirmedCases\nDate                                            \n2020-04-02         336318.015414    1.013264e+06\n2020-04-03          82744.000000    1.095922e+06\n2020-04-04          80254.000000    1.176089e+06\n2020-04-05          73825.000000    1.249834e+06\n2020-04-06          71858.000000    1.321604e+06\n2020-04-07          73852.000000    1.395367e+06\n2020-04-08          85154.000000    1.480422e+06\n2020-04-09          83751.000000    1.564019e+06\n2020-04-10          93826.000000    1.657752e+06\n2020-04-11          78213.000000    1.735848e+06\n2020-04-12          99255.000000    1.834987e+06\n2020-04-13          70131.000000    1.905015e+06\n2020-04-14          70563.000000    1.975404e+06\n2020-04-15          80023.000000    2.055327e+06\n2020-04-16          96685.000000    2.151902e+06\n2020-04-17          87855.000000    2.239544e+06\n2020-04-18          77739.000000    2.317159e+06\n2020-04-19          83930.000000    2.400991e+06\n2020-04-20          70935.000000    2.471667e+06\n2020-04-21          77447.000000    2.548995e+06\n2020-04-22          77789.000000    2.624430e+06\n2020-04-23          84041.000000    2.708367e+06\n2020-04-24          97573.000000    2.795670e+06\n2020-04-25          85550.000000    2.880960e+06\n2020-04-26          74003.000000    2.954851e+06\n2020-04-27          68848.000000    3.023542e+06\n2020-04-28          74107.000000    3.097010e+06\n2020-04-29          77728.000000    3.172102e+06\n2020-04-30          84658.000000    3.256652e+06\n2020-05-01          87034.000000    3.343574e+06\n2020-05-02          83792.000000    3.427074e+06\n2020-05-03          79463.000000    3.506408e+06\n2020-05-04          76334.000000    3.582630e+06\n2020-05-05          79678.000000    3.662193e+06\n2020-05-06          92672.000000    3.754748e+06\n2020-05-07            313.000000    3.754820e+06\n2020-05-08            313.000000    3.754894e+06\n2020-05-09            324.787841    3.754983e+06\n2020-05-10            314.508707    3.755060e+06\n2020-05-11            313.000000    3.755133e+06\n2020-05-12            313.000000    3.755202e+06\n2020-05-13            313.000000    3.755271e+06\n2020-05-14            313.000000    3.755338e+06\n            trend_Fatalities     Fatalities\nDate                                       \n2020-04-02           17034.0   53817.000000\n2020-04-03            6019.0   59648.000000\n2020-04-04            6064.0   65528.000000\n2020-04-05            4970.0   70315.000000\n2020-04-06            5517.0   75651.000000\n2020-04-07            7719.0   83187.000000\n2020-04-08            6765.0   89773.000000\n2020-04-09            7510.0   97099.000000\n2020-04-10            7437.0  104360.000000\n2020-04-11            6107.0  110260.000000\n2020-04-12            5714.0  115783.000000\n2020-04-13            5625.0  121216.000000\n2020-04-14            6981.0  128005.000000\n2020-04-15            8418.0  136246.000000\n2020-04-16            9972.0  146032.000000\n2020-04-17           10298.0  156163.000000\n2020-04-18            6146.0  162122.000000\n2020-04-19            5542.0  167486.000000\n2020-04-20            5231.0  172530.000000\n2020-04-21            7244.0  179592.000000\n2020-04-22            6706.0  186121.000000\n2020-04-23            7938.0  193891.000000\n2020-04-24            6735.0  200449.000000\n2020-04-25            5925.0  206181.000000\n2020-04-26            3889.0  209894.000000\n2020-04-27            4778.0  214478.000000\n2020-04-28            6513.0  220793.000000\n2020-04-29            7050.0  227659.000000\n2020-04-30            5863.0  233349.000000\n2020-05-01            5511.0  238611.000000\n2020-05-02            5427.0  243798.000000\n2020-05-03            3848.0  247460.000000\n2020-05-04            4254.0  251526.000000\n2020-05-05            5877.0  257224.000000\n2020-05-06            6769.0  263811.000000\n2020-05-07             313.0  263811.113375\n2020-05-08             313.0  263811.226749\n2020-05-09             313.0  263811.340124\n2020-05-10             313.0  263811.453498\n2020-05-11             313.0  263811.566873\n2020-05-12             313.0  263811.680247\n2020-05-13             313.0  263811.793622\n2020-05-14             313.0  263811.906996\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_date = train_df.groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_date = train_df.groupby(['Date']).agg({'Fatalities':['sum']})\nprint(confirmed_date)\nprint(fatalities_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train_df[train_df['Country_Region']=='Qatar'].tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def countryplot(train_df,country):\n    \n    confirmed_total = train_df[train_df['Country_Region']==country_dict[country]].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n    fatalities_total = train_df[train_df['Country_Region']==country_dict[country]].groupby(['Date']).agg({'Fatalities':['sum']})\n    total = confirmed_total.join(fatalities_total)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\n    total.plot(ax=ax1)\n    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90)\n    ax1.set_title(country + \" Forecast Confirmed Cases and Fatalities \", size=13,)\n    ax1.set_ylabel(\"Number of cases\", size=13)\n    ax1.set_xlabel(\"Date\", size=13)\n    #ax1.set_xticklabels(\"Date\",rotation= 90)\n    #plt.xticks(rotation=90)\n    ax1.grid()\n    fatalities_total.plot(ax=ax2, color='red')\n    plt.grid()\n    ax2.set_title(country+\" Forecast Fatalities\", size=13)\n    ax2.set_ylabel(\"Number of cases\", size=13)\n    ax2.set_xlabel(\"Date\", size=13)\n    plt.xticks(rotation=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countrylist=['Qatar','Italy','Spain','United Arab Emirates','Egypt','Germany','France','Korea, South','Turkey','US','Saudi Arabia','United Kingdom']\nfor co in countrylist:\n    countryplot(Predicted_data,co)\n    #country='Italy'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def countryplottotal(train_df):\n      \n    confirmed_total = train_df.groupby(['Date']).agg({'ConfirmedCases':['sum']})\n    fatalities_total = train_df.groupby(['Date']).agg({'Fatalities':['sum']})\n    total = confirmed_total.join(fatalities_total)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\n    total.plot(ax=ax1)\n    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90)\n    ax1.set_title(\"World Wide Forecast Confirmed Cases and Fatalities \", size=13,)\n    ax1.set_ylabel(\"Number of cases\", size=13)\n    ax1.set_xlabel(\"Date\", size=13)\n    #ax1.set_xticklabels(\"Date\",rotation= 90)\n    #plt.xticks(rotation=90)\n    ax1.grid()\n    fatalities_total.plot(ax=ax2, color='red')\n    plt.grid()\n    ax2.set_title(\"World Wide Forecast Fatalities\", size=13)\n    ax2.set_ylabel(\"Number of cases\", size=13)\n    ax2.set_xlabel(\"Date\", size=13)\n    plt.xticks(rotation=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"countryplottotal(Predicted_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def countryplothist(train_df,country):\n    \n    confirmed_total = train_df[train_df['Country_Region']==country_dict[country]].groupby(['Date']).agg({'trend_ConfirmedCases':['sum']})\n    fatalities_total = train_df[train_df['Country_Region']==country_dict[country]].groupby(['Date']).agg({'trend_Fatalities':['sum']})\n    total = confirmed_total.join(fatalities_total)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\n    total.plot(kind='bar',ax=ax1)\n    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90)\n    ax1.set_title(country + \" Forecast Confirmed Cases and Fatalities \", size=13,)\n    ax1.set_ylabel(\"Number of cases\", size=13)\n    ax1.set_xlabel(\"Date\", size=13)\n    #ax1.set_xticklabels(\"Date\",rotation= 90)\n    #plt.xticks(rotation=90)\n    ax1.grid()\n    fatalities_total.plot(kind='bar',ax=ax2, color='red')\n    plt.grid()\n    ax2.set_title(country+\" Forecast Fatalities\", size=13)\n    ax2.set_ylabel(\"Number of cases\", size=13)\n    ax2.set_xlabel(\"Date\", size=13)\n    plt.xticks(rotation=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"countrylist=['Qatar','Italy','Spain','United Arab Emirates','Egypt','Germany','France','Korea, South','Turkey','US','Saudi Arabia','United Kingdom']\nfor co in countrylist:\n    countryplothist(Predicted_data,co)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")\ndf['ConfirmedCases']=df['ConfirmedCases'].replace([-1], 0)\ndf['Fatalities']=df['Fatalities'].replace([-1], 0)\nsub_df = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\nsub_df[\"key\"]=sub_df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\ndf[\"key\"]=df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\nfeatures_columns = ['Id', 'Province_State', 'Country_Region', 'Date', 'ConfirmedCases',\n       'Fatalities','mean_rate_case_last7', 'mean_rate_case_last3',\n       'mean_rate_case_last10', 'mean_rate_fat_last10', 'mean_rate_case_last5',\n       'mean_rate_fat_last5', 'mean_rate_case_last14', 'mean_rate_fat_last14',\n       'mean_rate_case_last20', 'mean_rate_fat_last20', 'mean_rate_case_each7',\n       'mean_rate_case_each3', 'mean_rate_case_each9', 'mean_rate_case_each10',\n       'mean_rate_case_each13', 'mean_rate_fat_last7', 'mean_rate_fat_last3',\n       'mean_rate_fat_each7', 'mean_rate_fat_each3', 'mean_rate_fat_each9',\n       'mean_rate_fat_each13', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat','Lat','Long',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat',\n       'max_to_min_rate_fat', 'cases_prev', 'fat_prev', 'rate_ConfirmedCases',\n       'rate_Fatalities', 'mean_rate_fat_each10',  'total_pop', 'smokers_perc', 'density']\n\n  \ncoo_df = merged_train_df.groupby(\"key\")[['mean_rate_case_last7', 'mean_rate_case_last3',\n       'mean_rate_case_last10', 'mean_rate_fat_last10', 'mean_rate_case_last5',\n       'mean_rate_fat_last5', 'mean_rate_case_last14', 'mean_rate_fat_last14',\n       'mean_rate_case_last20', 'mean_rate_fat_last20', 'mean_rate_case_each7',\n       'mean_rate_case_each3', 'mean_rate_case_each9', 'mean_rate_case_each10',\n       'mean_rate_case_each13', 'mean_rate_fat_last7', 'mean_rate_fat_last3',\n       'mean_rate_fat_each7', 'mean_rate_fat_each3', 'mean_rate_fat_each9',\n      'mean_rate_fat_each13', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat','Lat','Long',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat',\n       'max_to_min_rate_fat', 'cases_prev', 'fat_prev', 'rate_ConfirmedCases',\n       'rate_Fatalities', 'mean_rate_fat_each10', 'total_pop', 'smokers_perc', 'density']].mean().reset_index()\n \n\nloc_group = [\"Province_State\", \"Country_Region\"]\n    #loc_group = [\"key\"]\n   # merged_train_df['Date']= pd.to_datetime(merged_train_df['Date']) \n  #  merged_train_df[\"days\"] = (merged_train_df[\"Date\"] - pd.to_datetime(\"2020-01-01\")).dt.days\n\ndef preprocess(df):\n    df[\"Date\"] = df[\"Date\"].astype(\"datetime64[ms]\")\n\n    df = df.merge(grouped_countries, how=\"left\", on=\"key\")\n  \n    df[\"Lat\"] = (df[\"Lat\"] // 30).astype(np.float32).fillna(0)\n    df[\"Long\"] = (df[\"Long\"] // 60).astype(np.float32).fillna(0)\n\n    for col in loc_group:\n        \n        df[col].fillna(\"none\", inplace=True)\n    return df\n\n\ndf = preprocess(df)\nsub_df = preprocess(sub_df)","execution_count":299,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = df.merge(sub_df, how=\"left\", on=\"key\")\n#df_traintest=df.copy()\ndf_traintest = pd.concat([df, sub_df])\nprint(df.shape,sub_df.shape, df_traintest.shape)","execution_count":300,"outputs":[{"output_type":"stream","text":"(33178, 41) (13459, 39) (46637, 42)\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_traintest","execution_count":302,"outputs":[{"output_type":"execute_result","execution_count":302,"data":{"text/plain":"       ConfirmedCases Country_Region       Date  Fatalities  ForecastId   Id  \\\n0                 0.0    Afghanistan 2020-01-22         0.0         NaN  1.0   \n1                 0.0    Afghanistan 2020-01-23         0.0         NaN  2.0   \n2                 0.0    Afghanistan 2020-01-24         0.0         NaN  3.0   \n3                 0.0    Afghanistan 2020-01-25         0.0         NaN  4.0   \n4                 0.0    Afghanistan 2020-01-26         0.0         NaN  5.0   \n...               ...            ...        ...         ...         ...  ...   \n13454             NaN       Zimbabwe 2020-05-10         NaN     13455.0  NaN   \n13455             NaN       Zimbabwe 2020-05-11         NaN     13456.0  NaN   \n13456             NaN       Zimbabwe 2020-05-12         NaN     13457.0  NaN   \n13457             NaN       Zimbabwe 2020-05-13         NaN     13458.0  NaN   \n13458             NaN       Zimbabwe 2020-05-14         NaN     13459.0  NaN   \n\n       Lat  Long Province_State   age_0-4  ...  hospibed              key  \\\n0      1.0   1.0           none  0.145717  ...       0.5  nan_Afghanistan   \n1      1.0   1.0           none  0.145717  ...       0.5  nan_Afghanistan   \n2      1.0   1.0           none  0.145717  ...       0.5  nan_Afghanistan   \n3      1.0   1.0           none  0.145717  ...       0.5  nan_Afghanistan   \n4      1.0   1.0           none  0.145717  ...       0.5  nan_Afghanistan   \n...    ...   ...            ...       ...  ...       ...              ...   \n13454  0.0   0.0           none       NaN  ...       NaN     nan_Zimbabwe   \n13455  0.0   0.0           none       NaN  ...       NaN     nan_Zimbabwe   \n13456  0.0   0.0           none       NaN  ...       NaN     nan_Zimbabwe   \n13457  0.0   0.0           none       NaN  ...       NaN     nan_Zimbabwe   \n13458  0.0   0.0           none       NaN  ...       NaN     nan_Zimbabwe   \n\n        lung  malelung  quarantine  restrictions  schools  smokers_perc  \\\n0      37.62     39.33         0.0           0.0      0.0     21.389448   \n1      37.62     39.33         0.0           0.0      0.0     21.389448   \n2      37.62     39.33         0.0           0.0      0.0     21.389448   \n3      37.62     39.33         0.0           0.0      0.0     21.389448   \n4      37.62     39.33         0.0           0.0      0.0     21.389448   \n...      ...       ...         ...           ...      ...           ...   \n13454    NaN       NaN         NaN           NaN      NaN           NaN   \n13455    NaN       NaN         NaN           NaN      NaN           NaN   \n13456    NaN       NaN         NaN           NaN      NaN           NaN   \n13457    NaN       NaN         NaN           NaN      NaN           NaN   \n13458    NaN       NaN         NaN           NaN      NaN           NaN   \n\n       total_pop  urbanpop  \n0      38928.341      25.0  \n1      38928.341      25.0  \n2      38928.341      25.0  \n3      38928.341      25.0  \n4      38928.341      25.0  \n...          ...       ...  \n13454        NaN       NaN  \n13455        NaN       NaN  \n13456        NaN       NaN  \n13457        NaN       NaN  \n13458        NaN       NaN  \n\n[46637 rows x 42 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ConfirmedCases</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>Fatalities</th>\n      <th>ForecastId</th>\n      <th>Id</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Province_State</th>\n      <th>age_0-4</th>\n      <th>...</th>\n      <th>hospibed</th>\n      <th>key</th>\n      <th>lung</th>\n      <th>malelung</th>\n      <th>quarantine</th>\n      <th>restrictions</th>\n      <th>schools</th>\n      <th>smokers_perc</th>\n      <th>total_pop</th>\n      <th>urbanpop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>2020-01-22</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>nan_Afghanistan</td>\n      <td>37.62</td>\n      <td>39.33</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.389448</td>\n      <td>38928.341</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>2020-01-23</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>nan_Afghanistan</td>\n      <td>37.62</td>\n      <td>39.33</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.389448</td>\n      <td>38928.341</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>2020-01-24</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>nan_Afghanistan</td>\n      <td>37.62</td>\n      <td>39.33</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.389448</td>\n      <td>38928.341</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>2020-01-25</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>nan_Afghanistan</td>\n      <td>37.62</td>\n      <td>39.33</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.389448</td>\n      <td>38928.341</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>Afghanistan</td>\n      <td>2020-01-26</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>nan_Afghanistan</td>\n      <td>37.62</td>\n      <td>39.33</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.389448</td>\n      <td>38928.341</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13454</th>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-10</td>\n      <td>NaN</td>\n      <td>13455.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>nan_Zimbabwe</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13455</th>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-11</td>\n      <td>NaN</td>\n      <td>13456.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>nan_Zimbabwe</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13456</th>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-12</td>\n      <td>NaN</td>\n      <td>13457.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>nan_Zimbabwe</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13457</th>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-13</td>\n      <td>NaN</td>\n      <td>13458.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>nan_Zimbabwe</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13458</th>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-14</td>\n      <td>NaN</td>\n      <td>13459.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>nan_Zimbabwe</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>46637 rows  42 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def func(x):\n    try:\n        x_new = x['Country_Region'] + \"_\" + x['Province_State']\n    except:\n        x_new = x['Country_Region']\n    return x_new","execution_count":303,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest['day'] = df_traintest['Date'].apply(lambda x: x.dayofyear).astype(np.int16)","execution_count":304,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest['place_id'] = df_traintest.apply(lambda x: func(x), axis=1)","execution_count":305,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"places = np.sort(df_traintest['place_id'].unique())\nprint(len(places))","execution_count":306,"outputs":[{"output_type":"stream","text":"313\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":290,"outputs":[{"output_type":"execute_result","execution_count":290,"data":{"text/plain":"   ForecastId Province_State Country_Region        Date              key\n0           1            NaN    Afghanistan  2020-04-02  nan_Afghanistan\n1           2            NaN    Afghanistan  2020-04-03  nan_Afghanistan\n2           3            NaN    Afghanistan  2020-04-04  nan_Afghanistan\n3           4            NaN    Afghanistan  2020-04-05  nan_Afghanistan\n4           5            NaN    Afghanistan  2020-04-06  nan_Afghanistan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ForecastId</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-04-02</td>\n      <td>nan_Afghanistan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-04-03</td>\n      <td>nan_Afghanistan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-04-04</td>\n      <td>nan_Afghanistan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-04-05</td>\n      <td>nan_Afghanistan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-04-06</td>\n      <td>nan_Afghanistan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":289,"outputs":[{"output_type":"execute_result","execution_count":289,"data":{"text/plain":"          Id Province_State Country_Region        Date  ConfirmedCases  \\\n33173  35670            NaN       Zimbabwe  2020-05-02            34.0   \n33174  35671            NaN       Zimbabwe  2020-05-03            34.0   \n33175  35672            NaN       Zimbabwe  2020-05-04            34.0   \n33176  35673            NaN       Zimbabwe  2020-05-05            34.0   \n33177  35674            NaN       Zimbabwe  2020-05-06            34.0   \n\n       Fatalities           key  \n33173         4.0  nan_Zimbabwe  \n33174         4.0  nan_Zimbabwe  \n33175         4.0  nan_Zimbabwe  \n33176         4.0  nan_Zimbabwe  \n33177         4.0  nan_Zimbabwe  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>ConfirmedCases</th>\n      <th>Fatalities</th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33173</th>\n      <td>35670</td>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-02</td>\n      <td>34.0</td>\n      <td>4.0</td>\n      <td>nan_Zimbabwe</td>\n    </tr>\n    <tr>\n      <th>33174</th>\n      <td>35671</td>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-03</td>\n      <td>34.0</td>\n      <td>4.0</td>\n      <td>nan_Zimbabwe</td>\n    </tr>\n    <tr>\n      <th>33175</th>\n      <td>35672</td>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-04</td>\n      <td>34.0</td>\n      <td>4.0</td>\n      <td>nan_Zimbabwe</td>\n    </tr>\n    <tr>\n      <th>33176</th>\n      <td>35673</td>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-05</td>\n      <td>34.0</td>\n      <td>4.0</td>\n      <td>nan_Zimbabwe</td>\n    </tr>\n    <tr>\n      <th>33177</th>\n      <td>35674</td>\n      <td>NaN</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-06</td>\n      <td>34.0</td>\n      <td>4.0</td>\n      <td>nan_Zimbabwe</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"day_before_private = df_traintest['day'][pd.isna(df_traintest['ForecastId'])].max() # last day of train\nday_before_public=day_before_private-35\nday_before_valid=day_before_public-7\n\n\nprint(df_traintest['Date'][df_traintest['day']==day_before_valid].values[0]) # the7 days before the public\nprint(df_traintest['Date'][df_traintest['day']==day_before_public].values[0])#the day before the first date of the test\nprint(df_traintest['Date'][df_traintest['day']==day_before_private].values[0])#last date in the train","execution_count":381,"outputs":[{"output_type":"stream","text":"2020-03-25T00:00:00.000000000\n2020-04-01T00:00:00.000000000\n2020-05-06T00:00:00.000000000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest2 = df_traintest.copy()\ndf_traintest2['cases/day'] = 0\ndf_traintest2['fatal/day'] = 0\ntmp_list = np.zeros(len(df_traintest2))\nfor place in places:\n    tmp = df_traintest2['ConfirmedCases'][df_traintest2['place_id']==place].values\n    tmp[1:] -= tmp[:-1]\n    df_traintest2['cases/day'][df_traintest2['place_id']==place] = tmp\n    tmp = df_traintest2['Fatalities'][df_traintest2['place_id']==place].values\n    tmp[1:] -= tmp[:-1]\n    df_traintest2['fatal/day'][df_traintest2['place_id']==place] = tmp\nprint(df_traintest2.shape)\ndf_traintest2[df_traintest2['place_id']=='US_New York'].tail(20)","execution_count":308,"outputs":[{"output_type":"stream","text":"(46637, 46)\n","name":"stdout"},{"output_type":"execute_result","execution_count":308,"data":{"text/plain":"       ConfirmedCases Country_Region       Date  Fatalities  ForecastId  Id  \\\n11633             NaN             US 2020-04-25         NaN     11634.0 NaN   \n11634             NaN             US 2020-04-26         NaN     11635.0 NaN   \n11635             NaN             US 2020-04-27         NaN     11636.0 NaN   \n11636             NaN             US 2020-04-28         NaN     11637.0 NaN   \n11637             NaN             US 2020-04-29         NaN     11638.0 NaN   \n11638             NaN             US 2020-04-30         NaN     11639.0 NaN   \n11639             NaN             US 2020-05-01         NaN     11640.0 NaN   \n11640             NaN             US 2020-05-02         NaN     11641.0 NaN   \n11641             NaN             US 2020-05-03         NaN     11642.0 NaN   \n11642             NaN             US 2020-05-04         NaN     11643.0 NaN   \n11643             NaN             US 2020-05-05         NaN     11644.0 NaN   \n11644             NaN             US 2020-05-06         NaN     11645.0 NaN   \n11645             NaN             US 2020-05-07         NaN     11646.0 NaN   \n11646             NaN             US 2020-05-08         NaN     11647.0 NaN   \n11647             NaN             US 2020-05-09         NaN     11648.0 NaN   \n11648             NaN             US 2020-05-10         NaN     11649.0 NaN   \n11649             NaN             US 2020-05-11         NaN     11650.0 NaN   \n11650             NaN             US 2020-05-12         NaN     11651.0 NaN   \n11651             NaN             US 2020-05-13         NaN     11652.0 NaN   \n11652             NaN             US 2020-05-14         NaN     11653.0 NaN   \n\n       Lat  Long Province_State  age_0-4  ...  quarantine  restrictions  \\\n11633  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11634  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11635  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11636  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11637  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11638  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11639  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11640  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11641  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11642  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11643  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11644  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11645  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11646  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11647  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11648  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11649  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11650  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11651  0.0   0.0       New York      NaN  ...         NaN           NaN   \n11652  0.0   0.0       New York      NaN  ...         NaN           NaN   \n\n       schools  smokers_perc  total_pop  urbanpop  day     place_id  \\\n11633      NaN           NaN        NaN       NaN  116  US_New York   \n11634      NaN           NaN        NaN       NaN  117  US_New York   \n11635      NaN           NaN        NaN       NaN  118  US_New York   \n11636      NaN           NaN        NaN       NaN  119  US_New York   \n11637      NaN           NaN        NaN       NaN  120  US_New York   \n11638      NaN           NaN        NaN       NaN  121  US_New York   \n11639      NaN           NaN        NaN       NaN  122  US_New York   \n11640      NaN           NaN        NaN       NaN  123  US_New York   \n11641      NaN           NaN        NaN       NaN  124  US_New York   \n11642      NaN           NaN        NaN       NaN  125  US_New York   \n11643      NaN           NaN        NaN       NaN  126  US_New York   \n11644      NaN           NaN        NaN       NaN  127  US_New York   \n11645      NaN           NaN        NaN       NaN  128  US_New York   \n11646      NaN           NaN        NaN       NaN  129  US_New York   \n11647      NaN           NaN        NaN       NaN  130  US_New York   \n11648      NaN           NaN        NaN       NaN  131  US_New York   \n11649      NaN           NaN        NaN       NaN  132  US_New York   \n11650      NaN           NaN        NaN       NaN  133  US_New York   \n11651      NaN           NaN        NaN       NaN  134  US_New York   \n11652      NaN           NaN        NaN       NaN  135  US_New York   \n\n                 cases/day            fatal/day  \n11633 -9223372036854775808 -9223372036854775808  \n11634 -9223372036854775808 -9223372036854775808  \n11635 -9223372036854775808 -9223372036854775808  \n11636 -9223372036854775808 -9223372036854775808  \n11637 -9223372036854775808 -9223372036854775808  \n11638 -9223372036854775808 -9223372036854775808  \n11639 -9223372036854775808 -9223372036854775808  \n11640 -9223372036854775808 -9223372036854775808  \n11641 -9223372036854775808 -9223372036854775808  \n11642 -9223372036854775808 -9223372036854775808  \n11643 -9223372036854775808 -9223372036854775808  \n11644 -9223372036854775808 -9223372036854775808  \n11645 -9223372036854775808 -9223372036854775808  \n11646 -9223372036854775808 -9223372036854775808  \n11647 -9223372036854775808 -9223372036854775808  \n11648 -9223372036854775808 -9223372036854775808  \n11649 -9223372036854775808 -9223372036854775808  \n11650 -9223372036854775808 -9223372036854775808  \n11651 -9223372036854775808 -9223372036854775808  \n11652 -9223372036854775808 -9223372036854775808  \n\n[20 rows x 46 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ConfirmedCases</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>Fatalities</th>\n      <th>ForecastId</th>\n      <th>Id</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Province_State</th>\n      <th>age_0-4</th>\n      <th>...</th>\n      <th>quarantine</th>\n      <th>restrictions</th>\n      <th>schools</th>\n      <th>smokers_perc</th>\n      <th>total_pop</th>\n      <th>urbanpop</th>\n      <th>day</th>\n      <th>place_id</th>\n      <th>cases/day</th>\n      <th>fatal/day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11633</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-04-25</td>\n      <td>NaN</td>\n      <td>11634.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>116</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11634</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-04-26</td>\n      <td>NaN</td>\n      <td>11635.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>117</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11635</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-04-27</td>\n      <td>NaN</td>\n      <td>11636.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>118</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11636</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-04-28</td>\n      <td>NaN</td>\n      <td>11637.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>119</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11637</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-04-29</td>\n      <td>NaN</td>\n      <td>11638.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>120</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11638</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-04-30</td>\n      <td>NaN</td>\n      <td>11639.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>121</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11639</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-01</td>\n      <td>NaN</td>\n      <td>11640.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>122</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11640</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-02</td>\n      <td>NaN</td>\n      <td>11641.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>123</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11641</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-03</td>\n      <td>NaN</td>\n      <td>11642.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>124</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11642</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-04</td>\n      <td>NaN</td>\n      <td>11643.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>125</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11643</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-05</td>\n      <td>NaN</td>\n      <td>11644.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>126</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11644</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-06</td>\n      <td>NaN</td>\n      <td>11645.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>127</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11645</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-07</td>\n      <td>NaN</td>\n      <td>11646.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>128</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11646</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-08</td>\n      <td>NaN</td>\n      <td>11647.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>129</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11647</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-09</td>\n      <td>NaN</td>\n      <td>11648.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>130</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11648</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-10</td>\n      <td>NaN</td>\n      <td>11649.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>131</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11649</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-11</td>\n      <td>NaN</td>\n      <td>11650.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>132</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11650</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-12</td>\n      <td>NaN</td>\n      <td>11651.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>133</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11651</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-13</td>\n      <td>NaN</td>\n      <td>11652.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>134</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n    <tr>\n      <th>11652</th>\n      <td>NaN</td>\n      <td>US</td>\n      <td>2020-05-14</td>\n      <td>NaN</td>\n      <td>11653.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>135</td>\n      <td>US_New York</td>\n      <td>-9223372036854775808</td>\n      <td>-9223372036854775808</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows  46 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_aggregation(df, col, mean_range):\n    df_new = df.copy()\n    col_new = '{}_({}-{})'.format(col, mean_range[0], mean_range[1])\n    df_new[col_new] = 0\n    tmp = df_new[col].rolling(mean_range[1]-mean_range[0]+1).mean()\n    df_new[col_new][mean_range[0]:] = tmp[:-(mean_range[0])]\n    df_new[col_new][pd.isna(df_new[col_new])] = 0\n    return df_new[[col_new]].reset_index(drop=True)\n\ndef do_aggregations(df):\n    df = pd.concat([df, do_aggregation(df, 'cases/day', [1,1]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'cases/day', [1,7]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'cases/day', [8,14]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'cases/day', [15,21]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'fatal/day', [1,1]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'fatal/day', [1,7]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'fatal/day', [8,14]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'fatal/day', [15,21]).reset_index(drop=True)], axis=1)\n    for threshold in [1, 10, 100]:\n        days_under_threshold = (df['ConfirmedCases']<threshold).sum()\n        tmp = df['day'].values - 22 - days_under_threshold\n        tmp[tmp<=0] = 0\n        df['days_since_{}cases'.format(threshold)] = tmp\n            \n    for threshold in [1, 10, 100]:\n        days_under_threshold = (df['Fatalities']<threshold).sum()\n        tmp = df['day'].values - 22 - days_under_threshold\n        tmp[tmp<=0] = 0\n        df['days_since_{}fatal'.format(threshold)] = tmp\n    \n    # process China/Hubei\n    if df['place_id'][0]=='China/Hubei':\n        df['days_since_1cases'] += 35 # 2019/12/8\n        df['days_since_10cases'] += 35-13 # 2019/12/8-2020/1/2 assume 2019/12/8+13\n        df['days_since_100cases'] += 4 # 2020/1/18\n        df['days_since_1fatal'] += 13 # 2020/1/9\n    return df","execution_count":309,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_traintest3 = []\nfor place in places[:]:\n    df_tmp = df_traintest2[df_traintest2['place_id']==place].reset_index(drop=True)\n    df_tmp = do_aggregations(df_tmp)\n    df_traintest3.append(df_tmp)\ndf_traintest3 = pd.concat(df_traintest3).reset_index(drop=True)\ndf_traintest3[df_traintest3['place_id']=='China/Hubei'].head()","execution_count":310,"outputs":[{"output_type":"execute_result","execution_count":310,"data":{"text/plain":"Empty DataFrame\nColumns: [ConfirmedCases, Country_Region, Date, Fatalities, ForecastId, Id, Lat, Long, Province_State, age_0-4, age_10-14, age_100+, age_15-19, age_20-24, age_25-29, age_30-34, age_35-39, age_40-44, age_45-49, age_5-9, age_50-54, age_55-59, age_60-64, age_65-69, age_70-74, age_75-79, age_80-84, age_85-89, age_90-94, age_95-99, density, femalelung, hospibed, key, lung, malelung, quarantine, restrictions, schools, smokers_perc, total_pop, urbanpop, day, place_id, cases/day, fatal/day, cases/day_(1-1), cases/day_(1-7), cases/day_(8-14), cases/day_(15-21), fatal/day_(1-1), fatal/day_(1-7), fatal/day_(8-14), fatal/day_(15-21), days_since_1cases, days_since_10cases, days_since_100cases, days_since_1fatal, days_since_10fatal, days_since_100fatal]\nIndex: []\n\n[0 rows x 60 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ConfirmedCases</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>Fatalities</th>\n      <th>ForecastId</th>\n      <th>Id</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Province_State</th>\n      <th>age_0-4</th>\n      <th>...</th>\n      <th>fatal/day_(1-1)</th>\n      <th>fatal/day_(1-7)</th>\n      <th>fatal/day_(8-14)</th>\n      <th>fatal/day_(15-21)</th>\n      <th>days_since_1cases</th>\n      <th>days_since_10cases</th>\n      <th>days_since_100cases</th>\n      <th>days_since_1fatal</th>\n      <th>days_since_10fatal</th>\n      <th>days_since_100fatal</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows  60 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_label(df, col, freq_limit=0):\n    df[col][pd.isna(df[col])] = 'nan'\n    tmp = df[col].value_counts()\n    cols = tmp.index.values\n    freq = tmp.values\n    num_cols = (freq>=freq_limit).sum()\n    print(\"col: {}, num_cat: {}, num_reduced: {}\".format(col, len(cols), num_cols))\n\n    col_new = '{}_le'.format(col)\n    df_new = pd.DataFrame(np.ones(len(df), np.int16)*(num_cols-1), columns=[col_new])\n    for i, item in enumerate(cols[:num_cols]):\n        df_new[col_new][df[col]==item] = i\n\n    return df_new\n\ndef get_df_le(df, col_index, col_cat):\n    df_new = df[[col_index]]\n    for col in col_cat:\n        df_tmp = encode_label(df, col)\n        df_new = pd.concat([df_new, df_tmp], axis=1)\n    return df_new\n\ndf_traintest3['id'] = np.arange(len(df_traintest3))\ndf_le = get_df_le(df_traintest3, 'id', ['Country_Region', 'Province_State'])\ndf_traintest4 = pd.merge(df_traintest3, df_le, on='id', how='left')","execution_count":311,"outputs":[{"output_type":"stream","text":"col: Country_Region, num_cat: 184, num_reduced: 184\ncol: Province_State, num_cat: 134, num_reduced: 134\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest4['cases/day'] = df_traintest4['cases/day'].astype(np.float)\ndf_traintest4['fatal/day'] = df_traintest4['fatal/day'].astype(np.float)","execution_count":312,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest = df_traintest4.copy()","execution_count":313,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_traintest['ForecastId'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_score(y_true, y_pred):\n    y_true[y_true<0] = 0\n    score = metrics.mean_squared_error(np.log(y_true.clip(0, 1e10)+1), np.log(y_pred[:]+1))**0.5\n    return score\nSEED = 42\nparams = {'num_leaves': 8,\n          'min_data_in_leaf': 5,  # 42,\n          'objective': 'regression',\n          'max_depth': 8,\n          'learning_rate': 0.02,\n          'boosting': 'gbdt',\n          'bagging_freq': 5,  # 5\n          'bagging_fraction': 0.8,  # 0.5,\n          'feature_fraction': 0.8201,\n          'bagging_seed': SEED,\n          'reg_alpha': 1,  # 1.728910519108444,\n          'reg_lambda': 4.9847051755586085,\n          'random_state': SEED,\n          'metric': 'mse',\n          'verbosity': 100,\n          'min_gain_to_split': 0.02,  # 0.01077313523861969,\n          'min_child_weight': 5,  # 19.428902804238373,\n          'num_threads': 6,\n          }","execution_count":314,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import os, gc, pickle, copy, datetime, warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn import metrics\ncol_target = 'fatal/day'\ncol_var = [\n'Lat', 'Long',\n'smokers_perc', 'density',\n    'cases/day_(1-1)', \n    'cases/day_(1-7)', \n\n    'fatal/day_(1-7)', \n    'fatal/day_(8-14)', \n    'fatal/day_(15-21)'\n]\ncol_cat = []\ndf_train = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_valid)]\ndf_valid = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (day_before_valid<df_traintest['day'])& (df_traintest['day']<=(day_before_public))]\ndf_test = df_traintest[pd.isna(df_traintest['ForecastId'])==False]\nX_train = df_train[col_var]\nX_valid = df_valid[col_var]\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\ntrain_data = lgb.Dataset(X_train, label=y_train, categorical_feature=col_cat)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=col_cat)\nnum_round = 15000\nmodel = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)\n\nbest_itr = model.best_iteration","execution_count":382,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 150 rounds\n[100]\ttraining's l2: 0.0400577\tvalid_1's l2: 0.259248\n[200]\ttraining's l2: 0.0318574\tvalid_1's l2: 0.196848\n[300]\ttraining's l2: 0.0296271\tvalid_1's l2: 0.194332\n[400]\ttraining's l2: 0.0282063\tvalid_1's l2: 0.197171\nEarly stopping, best iteration is:\n[260]\ttraining's l2: 0.0303236\tvalid_1's l2: 0.193848\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"y_true = df_valid['fatal/day'].values\ny_pred = np.exp(model.predict(X_valid))-1\nscore = calc_score(y_true, y_pred)\nprint(\"{:.6f}\".format(score))","execution_count":383,"outputs":[{"output_type":"stream","text":"0.440282\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"tmp = pd.DataFrame()\ntmp[\"feature\"] = col_var\ntmp[\"importance\"] = model.feature_importance()\ntmp = tmp.sort_values('importance', ascending=False)\ntmp","execution_count":317,"outputs":[{"output_type":"execute_result","execution_count":317,"data":{"text/plain":"             feature  importance\n6    fatal/day_(1-7)         572\n5    cases/day_(1-7)         270\n4    cases/day_(1-1)         112\n8  fatal/day_(15-21)         103\n7   fatal/day_(8-14)          94\n3            density          37\n2       smokers_perc          13\n1               Long           3\n0                Lat           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>fatal/day_(1-7)</td>\n      <td>572</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cases/day_(1-7)</td>\n      <td>270</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cases/day_(1-1)</td>\n      <td>112</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>fatal/day_(15-21)</td>\n      <td>103</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>fatal/day_(8-14)</td>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>density</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>smokers_perc</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Long</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Lat</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_train = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_public)]\ndf_valid = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_public)]\ndf_test = df_traintest[pd.isna(df_traintest['ForecastId'])==False]\nX_train = df_train[col_var]\nX_valid = df_valid[col_var]\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\ntrain_data = lgb.Dataset(X_train, label=y_train, categorical_feature=col_cat)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=col_cat)\nmodel = lgb.train(params, train_data, best_itr, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)","execution_count":384,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 150 rounds\n[100]\ttraining's l2: 0.0573425\tvalid_1's l2: 0.0573425\n[200]\ttraining's l2: 0.046612\tvalid_1's l2: 0.046612\nDid not meet early stopping. Best iteration is:\n[260]\ttraining's l2: 0.0450911\tvalid_1's l2: 0.0450911\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"col_target2 = 'cases/day'\ncol_var2 = [\n'Lat', 'Long',\n'smokers_perc', 'density',\n'days_since_10cases', #selected\n\n    'cases/day_(1-1)', \n    'cases/day_(1-7)', \n    'cases/day_(8-14)',  \n    'cases/day_(15-21)'\n]\ncol_cat = []\ndf_train = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_valid)]\ndf_valid = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (day_before_valid<df_traintest['day']) & (df_traintest['day']<=day_before_public)]\nX_train = df_train[col_var2]\nX_valid = df_valid[col_var2]\ny_train = np.log(df_train[col_target2].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target2].values.clip(0, 1e10)+1)\ntrain_data = lgb.Dataset(X_train, label=y_train, categorical_feature=col_cat)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=col_cat)\nmodel2 = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)\nbest_itr2 = model2.best_iteration","execution_count":385,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 150 rounds\n[100]\ttraining's l2: 0.32426\tvalid_1's l2: 0.940213\n[200]\ttraining's l2: 0.274893\tvalid_1's l2: 0.714612\n[300]\ttraining's l2: 0.265383\tvalid_1's l2: 0.70225\n[400]\ttraining's l2: 0.259402\tvalid_1's l2: 0.703083\nEarly stopping, best iteration is:\n[335]\ttraining's l2: 0.263178\tvalid_1's l2: 0.700164\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = df_valid['cases/day'].values\ny_pred = np.exp(model2.predict(X_valid))-1\nscore = calc_score(y_true, y_pred)\nprint(\"{:.6f}\".format(score))","execution_count":386,"outputs":[{"output_type":"stream","text":"0.836758\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = pd.DataFrame()\ntmp[\"feature\"] = col_var2\ntmp[\"importance\"] = model2.feature_importance()\ntmp = tmp.sort_values('importance', ascending=False)\ntmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_train = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_public)]\ndf_valid = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_public)]\nX_train = df_train[col_var2]\nX_valid = df_valid[col_var2]\ny_train = np.log(df_train[col_target2].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target2].values.clip(0, 1e10)+1)\ntrain_data = lgb.Dataset(X_train, label=y_train, categorical_feature=col_cat)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=col_cat)\nmodel2 = lgb.train(params, train_data, best_itr2, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)","execution_count":387,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 150 rounds\n[100]\ttraining's l2: 0.379998\tvalid_1's l2: 0.379998\n[200]\ttraining's l2: 0.317443\tvalid_1's l2: 0.317443\n[300]\ttraining's l2: 0.307682\tvalid_1's l2: 0.307682\nDid not meet early stopping. Best iteration is:\n[335]\ttraining's l2: 0.305657\tvalid_1's l2: 0.305657\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_valid = df_traintest[(pd.isna(df_traintest['ForecastId'])) & ((day_before_public)<df_traintest['day'])]\ndf_valid","execution_count":388,"outputs":[{"output_type":"execute_result","execution_count":388,"data":{"text/plain":"       ConfirmedCases Country_Region       Date  Fatalities  ForecastId  \\\n71              273.0    Afghanistan 2020-04-02         6.0         NaN   \n72              281.0    Afghanistan 2020-04-03         6.0         NaN   \n73              299.0    Afghanistan 2020-04-04         7.0         NaN   \n74              349.0    Afghanistan 2020-04-05         7.0         NaN   \n75              367.0    Afghanistan 2020-04-06        11.0         NaN   \n...               ...            ...        ...         ...         ...   \n46589            34.0       Zimbabwe 2020-05-02         4.0         NaN   \n46590            34.0       Zimbabwe 2020-05-03         4.0         NaN   \n46591            34.0       Zimbabwe 2020-05-04         4.0         NaN   \n46592            34.0       Zimbabwe 2020-05-05         4.0         NaN   \n46593            34.0       Zimbabwe 2020-05-06         4.0         NaN   \n\n            Id  Lat  Long Province_State   age_0-4  ...  fatal/day_(15-21)  \\\n71        72.0  1.0   1.0           none  0.145717  ...           0.000000   \n72        73.0  1.0   1.0           none  0.145717  ...           0.000000   \n73        74.0  1.0   1.0           none  0.145717  ...           0.000000   \n74        75.0  1.0   1.0           none  0.145717  ...           0.000000   \n75        76.0  1.0   1.0           none  0.145717  ...           0.142857   \n...        ...  ...   ...            ...       ...  ...                ...   \n46589  35670.0  0.0   0.0           none       NaN  ...           0.000000   \n46590  35671.0  0.0   0.0           none       NaN  ...           0.000000   \n46591  35672.0  0.0   0.0           none       NaN  ...           0.000000   \n46592  35673.0  0.0   0.0           none       NaN  ...           0.000000   \n46593  35674.0  0.0   0.0           none       NaN  ...           0.000000   \n\n       days_since_1cases  days_since_10cases  days_since_100cases  \\\n71                    38                  19                    6   \n72                    39                  20                    7   \n73                    40                  21                    8   \n74                    41                  22                    9   \n75                    42                  23                   10   \n...                  ...                 ...                  ...   \n46589                 43                  26                    0   \n46590                 44                  27                    0   \n46591                 45                  28                    0   \n46592                 46                  29                    0   \n46593                 47                  30                    0   \n\n       days_since_1fatal  days_since_10fatal  days_since_100fatal     id  \\\n71                    11                   0                    0     71   \n72                    12                   0                    0     72   \n73                    13                   0                    0     73   \n74                    14                   0                    0     74   \n75                    15                   0                    0     75   \n...                  ...                 ...                  ...    ...   \n46589                 40                   0                    0  46589   \n46590                 41                   0                    0  46590   \n46591                 42                   0                    0  46591   \n46592                 43                   0                    0  46592   \n46593                 44                   0                    0  46593   \n\n       Country_Region_le  Province_State_le  \n71                   168                  0  \n72                   168                  0  \n73                   168                  0  \n74                   168                  0  \n75                   168                  0  \n...                  ...                ...  \n46589                 79                  0  \n46590                 79                  0  \n46591                 79                  0  \n46592                 79                  0  \n46593                 79                  0  \n\n[10955 rows x 63 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ConfirmedCases</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>Fatalities</th>\n      <th>ForecastId</th>\n      <th>Id</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Province_State</th>\n      <th>age_0-4</th>\n      <th>...</th>\n      <th>fatal/day_(15-21)</th>\n      <th>days_since_1cases</th>\n      <th>days_since_10cases</th>\n      <th>days_since_100cases</th>\n      <th>days_since_1fatal</th>\n      <th>days_since_10fatal</th>\n      <th>days_since_100fatal</th>\n      <th>id</th>\n      <th>Country_Region_le</th>\n      <th>Province_State_le</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>71</th>\n      <td>273.0</td>\n      <td>Afghanistan</td>\n      <td>2020-04-02</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>72.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>38</td>\n      <td>19</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>71</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>281.0</td>\n      <td>Afghanistan</td>\n      <td>2020-04-03</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>73.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>39</td>\n      <td>20</td>\n      <td>7</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>299.0</td>\n      <td>Afghanistan</td>\n      <td>2020-04-04</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>74.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>40</td>\n      <td>21</td>\n      <td>8</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>73</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>349.0</td>\n      <td>Afghanistan</td>\n      <td>2020-04-05</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>75.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>41</td>\n      <td>22</td>\n      <td>9</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>74</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>367.0</td>\n      <td>Afghanistan</td>\n      <td>2020-04-06</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>76.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>42</td>\n      <td>23</td>\n      <td>10</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>75</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>46589</th>\n      <td>34.0</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-02</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>35670.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>43</td>\n      <td>26</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>46589</td>\n      <td>79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46590</th>\n      <td>34.0</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-03</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>35671.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>44</td>\n      <td>27</td>\n      <td>0</td>\n      <td>41</td>\n      <td>0</td>\n      <td>0</td>\n      <td>46590</td>\n      <td>79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46591</th>\n      <td>34.0</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-04</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>35672.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>45</td>\n      <td>28</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>46591</td>\n      <td>79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46592</th>\n      <td>34.0</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-05</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>35673.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>46</td>\n      <td>29</td>\n      <td>0</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>46592</td>\n      <td>79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46593</th>\n      <td>34.0</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-06</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>35674.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>47</td>\n      <td>30</td>\n      <td>0</td>\n      <td>44</td>\n      <td>0</td>\n      <td>0</td>\n      <td>46593</td>\n      <td>79</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10955 rows  63 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# train model to predict fatalities/day\ndf_train = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_public)]\ndf_valid = df_traintest[(pd.isna(df_traintest['ForecastId'])) & ((day_before_public)<df_traintest['day'])]\ndf_test = df_traintest[pd.isna(df_traintest['ForecastId'])==False]\nX_train = df_train[col_var]\nX_valid = df_valid[col_var]\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\ntrain_data = lgb.Dataset(X_train, label=y_train, categorical_feature=col_cat)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=col_cat)\nnum_round = 15000\nmodel = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)\n\nbest_itr = model.best_iteration","execution_count":389,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 150 rounds\n[100]\ttraining's l2: 0.0573425\tvalid_1's l2: 0.292519\n[200]\ttraining's l2: 0.046612\tvalid_1's l2: 0.284098\nEarly stopping, best iteration is:\n[144]\ttraining's l2: 0.049573\tvalid_1's l2: 0.277878\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# train with all data\ndf_train = df_traintest[(pd.isna(df_traintest['ForecastId']))]\ndf_valid = df_traintest[(pd.isna(df_traintest['ForecastId']))]\nX_train = df_train[col_var]\nX_valid = df_valid[col_var]\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\ntrain_data = lgb.Dataset(X_train, label=y_train, categorical_feature=col_cat)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=col_cat)\nmodel_pri = lgb.train(params, train_data, best_itr, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)","execution_count":390,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 150 rounds\n[100]\ttraining's l2: 0.134761\tvalid_1's l2: 0.134761\nDid not meet early stopping. Best iteration is:\n[144]\ttraining's l2: 0.113892\tvalid_1's l2: 0.113892\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_train = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_public)]\ndf_valid = df_traintest[(pd.isna(df_traintest['ForecastId'])) & ((day_before_public-1)<df_traintest['day'])]\nX_train = df_train[col_var2]\nX_valid = df_valid[col_var2]\ny_train = np.log(df_train[col_target2].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target2].values.clip(0, 1e10)+1)\ntrain_data = lgb.Dataset(X_train, label=y_train, categorical_feature=col_cat)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=col_cat)\nmodel2 = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)\nbest_itr2 = model2.best_iteration","execution_count":391,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 150 rounds\n[100]\ttraining's l2: 0.379998\tvalid_1's l2: 0.937846\n[200]\ttraining's l2: 0.317443\tvalid_1's l2: 0.819472\n[300]\ttraining's l2: 0.307682\tvalid_1's l2: 0.822586\nEarly stopping, best iteration is:\n[218]\ttraining's l2: 0.314904\tvalid_1's l2: 0.818699\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# train with all data\ndf_train = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_public)]\ndf_valid = df_traintest[(pd.isna(df_traintest['ForecastId'])) & (df_traintest['day']<=day_before_public)]\nX_train = df_train[col_var2]\nX_valid = df_valid[col_var2]\ny_train = np.log(df_train[col_target2].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target2].values.clip(0, 1e10)+1)\ntrain_data = lgb.Dataset(X_train, label=y_train, categorical_feature=col_cat)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=col_cat)\nmodel2_pri = lgb.train(params, train_data, best_itr2, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)","execution_count":392,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 150 rounds\n[100]\ttraining's l2: 0.379998\tvalid_1's l2: 0.379998\n[200]\ttraining's l2: 0.317443\tvalid_1's l2: 0.317443\nDid not meet early stopping. Best iteration is:\n[218]\ttraining's l2: 0.314904\tvalid_1's l2: 0.314904\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_tmp = df_traintest[\n    ((df_traintest['day']<=day_before_public)  & (pd.isna(df_traintest['ForecastId'])))\n    | ((day_before_public<df_traintest['day']) & (pd.isna(df_traintest['ForecastId'])==False))].reset_index(drop=True)\n\ndf_traintest9 = []\nfor i, place in enumerate(places[:]):\n    df_tmp2 = df_tmp[df_tmp['place_id']==place].reset_index(drop=True)\n   # df_tmp2 = do_aggregations(df_tmp2)\n    df_traintest9.append(df_tmp2)\ndf_traintest9 = pd.concat(df_traintest9).reset_index(drop=True)\ndf_traintest9[df_traintest9['day']>day_before_public-2].head()","execution_count":393,"outputs":[{"output_type":"execute_result","execution_count":393,"data":{"text/plain":"    ConfirmedCases Country_Region       Date  Fatalities  ForecastId    Id  \\\n69           174.0    Afghanistan 2020-03-31         4.0         NaN  70.0   \n70           237.0    Afghanistan 2020-04-01         4.0         NaN  71.0   \n71             NaN    Afghanistan 2020-04-02         NaN         1.0   NaN   \n72             NaN    Afghanistan 2020-04-03         NaN         2.0   NaN   \n73             NaN    Afghanistan 2020-04-04         NaN         3.0   NaN   \n\n    Lat  Long Province_State   age_0-4  ...  fatal/day_(15-21)  \\\n69  1.0   1.0           none  0.145717  ...           0.000000   \n70  1.0   1.0           none  0.145717  ...           0.000000   \n71  1.0   1.0           none  0.145717  ...           2.142857   \n72  1.0   1.0           none  0.145717  ...           1.714286   \n73  1.0   1.0           none  0.145717  ...           1.857143   \n\n    days_since_1cases  days_since_10cases  days_since_100cases  \\\n69                 36                  17                    4   \n70                 37                  18                    5   \n71                 38                  19                    6   \n72                 39                  20                    7   \n73                 40                  21                    8   \n\n    days_since_1fatal  days_since_10fatal  days_since_100fatal   id  \\\n69                  9                   0                    0   69   \n70                 10                   0                    0   70   \n71                 11                   0                    0  106   \n72                 12                   0                    0  107   \n73                 13                   0                    0  108   \n\n    Country_Region_le  Province_State_le  \n69                168                  0  \n70                168                  0  \n71                168                  0  \n72                168                  0  \n73                168                  0  \n\n[5 rows x 63 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ConfirmedCases</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>Fatalities</th>\n      <th>ForecastId</th>\n      <th>Id</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Province_State</th>\n      <th>age_0-4</th>\n      <th>...</th>\n      <th>fatal/day_(15-21)</th>\n      <th>days_since_1cases</th>\n      <th>days_since_10cases</th>\n      <th>days_since_100cases</th>\n      <th>days_since_1fatal</th>\n      <th>days_since_10fatal</th>\n      <th>days_since_100fatal</th>\n      <th>id</th>\n      <th>Country_Region_le</th>\n      <th>Province_State_le</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>69</th>\n      <td>174.0</td>\n      <td>Afghanistan</td>\n      <td>2020-03-31</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>70.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>36</td>\n      <td>17</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>69</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>237.0</td>\n      <td>Afghanistan</td>\n      <td>2020-04-01</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>71.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>37</td>\n      <td>18</td>\n      <td>5</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>70</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-04-02</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>2.142857</td>\n      <td>38</td>\n      <td>19</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>106</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-04-03</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>1.714286</td>\n      <td>39</td>\n      <td>20</td>\n      <td>7</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>107</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-04-04</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>1.857143</td>\n      <td>40</td>\n      <td>21</td>\n      <td>8</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows  63 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# remove overlap for private LB prediction\ndf_tmp = df_traintest[\n    ((df_traintest['day']<=day_before_private)  & (pd.isna(df_traintest['ForecastId'])))\n    | ((day_before_private<df_traintest['day']) & (pd.isna(df_traintest['ForecastId'])==False))].reset_index(drop=True)\n\ndf_traintest10 = []\nfor i, place in enumerate(places[:]):\n    df_tmp2 = df_tmp[df_tmp['place_id']==place].reset_index(drop=True)\n\n    df_traintest10.append(df_tmp2)\ndf_traintest10 = pd.concat(df_traintest10).reset_index(drop=True)\ndf_traintest10[df_traintest10['day']>day_before_private-2].head()","execution_count":394,"outputs":[{"output_type":"execute_result","execution_count":394,"data":{"text/plain":"     ConfirmedCases Country_Region       Date  Fatalities  ForecastId     Id  \\\n104          3224.0    Afghanistan 2020-05-05        95.0         NaN  105.0   \n105          3392.0    Afghanistan 2020-05-06       104.0         NaN  106.0   \n106             NaN    Afghanistan 2020-05-07         NaN        36.0    NaN   \n107             NaN    Afghanistan 2020-05-08         NaN        37.0    NaN   \n108             NaN    Afghanistan 2020-05-09         NaN        38.0    NaN   \n\n     Lat  Long Province_State   age_0-4  ...  fatal/day_(15-21)  \\\n104  1.0   1.0           none  0.145717  ...       2.142857e+00   \n105  1.0   1.0           none  0.145717  ...       1.857143e+00   \n106  1.0   1.0           none  0.145717  ...      -9.223372e+18   \n107  1.0   1.0           none  0.145717  ...      -9.223372e+18   \n108  1.0   1.0           none  0.145717  ...      -9.223372e+18   \n\n     days_since_1cases  days_since_10cases  days_since_100cases  \\\n104                 71                  52                   39   \n105                 72                  53                   40   \n106                 73                  54                   41   \n107                 74                  55                   42   \n108                 75                  56                   43   \n\n     days_since_1fatal  days_since_10fatal  days_since_100fatal   id  \\\n104                 44                  29                    0  104   \n105                 45                  30                    0  105   \n106                 46                  31                    1  141   \n107                 47                  32                    2  142   \n108                 48                  33                    3  143   \n\n     Country_Region_le  Province_State_le  \n104                168                  0  \n105                168                  0  \n106                168                  0  \n107                168                  0  \n108                168                  0  \n\n[5 rows x 63 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ConfirmedCases</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>Fatalities</th>\n      <th>ForecastId</th>\n      <th>Id</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Province_State</th>\n      <th>age_0-4</th>\n      <th>...</th>\n      <th>fatal/day_(15-21)</th>\n      <th>days_since_1cases</th>\n      <th>days_since_10cases</th>\n      <th>days_since_100cases</th>\n      <th>days_since_1fatal</th>\n      <th>days_since_10fatal</th>\n      <th>days_since_100fatal</th>\n      <th>id</th>\n      <th>Country_Region_le</th>\n      <th>Province_State_le</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>104</th>\n      <td>3224.0</td>\n      <td>Afghanistan</td>\n      <td>2020-05-05</td>\n      <td>95.0</td>\n      <td>NaN</td>\n      <td>105.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>2.142857e+00</td>\n      <td>71</td>\n      <td>52</td>\n      <td>39</td>\n      <td>44</td>\n      <td>29</td>\n      <td>0</td>\n      <td>104</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>3392.0</td>\n      <td>Afghanistan</td>\n      <td>2020-05-06</td>\n      <td>104.0</td>\n      <td>NaN</td>\n      <td>106.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>1.857143e+00</td>\n      <td>72</td>\n      <td>53</td>\n      <td>40</td>\n      <td>45</td>\n      <td>30</td>\n      <td>0</td>\n      <td>105</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-05-07</td>\n      <td>NaN</td>\n      <td>36.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>-9.223372e+18</td>\n      <td>73</td>\n      <td>54</td>\n      <td>41</td>\n      <td>46</td>\n      <td>31</td>\n      <td>1</td>\n      <td>141</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-05-08</td>\n      <td>NaN</td>\n      <td>37.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>-9.223372e+18</td>\n      <td>74</td>\n      <td>55</td>\n      <td>42</td>\n      <td>47</td>\n      <td>32</td>\n      <td>2</td>\n      <td>142</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-05-09</td>\n      <td>NaN</td>\n      <td>38.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>-9.223372e+18</td>\n      <td>75</td>\n      <td>56</td>\n      <td>43</td>\n      <td>48</td>\n      <td>33</td>\n      <td>3</td>\n      <td>143</td>\n      <td>168</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows  63 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict test data in public\n# predict the cases and fatatilites one day at a time and use the predicts as next day's feature recursively.\ndf_preds = []\nfor i, place in enumerate(places[:]):\n    df_interest = copy.deepcopy(df_traintest9[df_traintest9['place_id']==place].reset_index(drop=True))\n    df_interest['cases/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    df_interest['fatal/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    len_known = (df_interest['day']<=day_before_public).sum()\n    len_unknown = (day_before_public<df_interest['day']).sum()\n    for j in range(len_unknown): # use predicted cases and fatal for next days' prediction\n        X_valid = df_interest[col_var].iloc[j+len_known]\n        X_valid2 = df_interest[col_var2].iloc[j+len_known]\n        pred_f = model.predict(X_valid)\n        pred_c = model2.predict(X_valid2)\n        pred_c = (np.exp(pred_c)-1).clip(0, 1e10)\n        pred_f = (np.exp(pred_f)-1).clip(0, 1e10)\n        df_interest['fatal/day'][j+len_known] = pred_f\n        df_interest['cases/day'][j+len_known] = pred_c\n        df_interest['Fatalities'][j+len_known] = df_interest['Fatalities'][j+len_known-1] + pred_f\n        df_interest['ConfirmedCases'][j+len_known] = df_interest['ConfirmedCases'][j+len_known-1] + pred_c\n#         print(df_interest['ConfirmedCases'][j+len_known-1], df_interest['ConfirmedCases'][j+len_known], pred_c)\n \n     \n    if (i+1)%10==0:\n        print(\"{:3d}/{}  {}, len known: {}, len unknown: {}\".format(i+1, len(places), place, len_known, len_unknown), df_interest.shape)\n    df_interest['fatal_pred'] = np.cumsum(df_interest['fatal/day'].values)\n    df_interest['cases_pred'] = np.cumsum(df_interest['cases/day'].values)\n    df_preds.append(df_interest)\ndf_preds = pd.concat(df_preds)","execution_count":395,"outputs":[{"output_type":"stream","text":" 10/313  Australia_New South Wales, len known: 71, len unknown: 43 (114, 63)\n 20/313  Bahrain_none, len known: 71, len unknown: 43 (114, 63)\n 30/313  Botswana_none, len known: 71, len unknown: 43 (114, 63)\n 40/313  Canada_Alberta, len known: 71, len unknown: 43 (114, 63)\n 50/313  Canada_Saskatchewan, len known: 71, len unknown: 43 (114, 63)\n 60/313  China_Guangdong, len known: 71, len unknown: 43 (114, 63)\n 70/313  China_Inner Mongolia, len known: 71, len unknown: 43 (114, 63)\n 80/313  China_Shanghai, len known: 71, len unknown: 43 (114, 63)\n 90/313  Congo (Kinshasa)_none, len known: 71, len unknown: 43 (114, 63)\n100/313  Diamond Princess_none, len known: 71, len unknown: 43 (114, 63)\n110/313  Eswatini_none, len known: 71, len unknown: 43 (114, 63)\n120/313  France_Reunion, len known: 71, len unknown: 43 (114, 63)\n130/313  Greece_none, len known: 71, len unknown: 43 (114, 63)\n140/313  Iceland_none, len known: 71, len unknown: 43 (114, 63)\n150/313  Jordan_none, len known: 71, len unknown: 43 (114, 63)\n160/313  Liberia_none, len known: 71, len unknown: 43 (114, 63)\n170/313  Mali_none, len known: 71, len unknown: 43 (114, 63)\n180/313  Mozambique_none, len known: 71, len unknown: 43 (114, 63)\n190/313  Niger_none, len known: 71, len unknown: 43 (114, 63)\n200/313  Philippines_none, len known: 71, len unknown: 43 (114, 63)\n210/313  San Marino_none, len known: 71, len unknown: 43 (114, 63)\n220/313  Somalia_none, len known: 71, len unknown: 43 (114, 63)\n230/313  Taiwan*_none, len known: 71, len unknown: 43 (114, 63)\n240/313  US_Arizona, len known: 71, len unknown: 43 (114, 63)\n250/313  US_Hawaii, len known: 71, len unknown: 43 (114, 63)\n260/313  US_Massachusetts, len known: 71, len unknown: 43 (114, 63)\n270/313  US_New Mexico, len known: 71, len unknown: 43 (114, 63)\n280/313  US_South Carolina, len known: 71, len unknown: 43 (114, 63)\n290/313  US_Wisconsin, len known: 71, len unknown: 43 (114, 63)\n300/313  United Kingdom_Falkland Islands (Malvinas), len known: 71, len unknown: 43 (114, 63)\n310/313  West Bank and Gaza_none, len known: 71, len unknown: 43 (114, 63)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict test data in public\ndf_preds_pri = []\nfor i, place in enumerate(places[:]):\n    df_interest = copy.deepcopy(df_traintest10[df_traintest10['place_id']==place].reset_index(drop=True))\n    df_interest['cases/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    df_interest['fatal/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    len_known = (df_interest['day']<=day_before_private).sum()\n    len_unknown = (day_before_private<df_interest['day']).sum()\n    for j in range(len_unknown): # use predicted cases and fatal for next days' prediction\n        X_valid = df_interest[col_var].iloc[j+len_known]\n        X_valid2 = df_interest[col_var2].iloc[j+len_known]\n        pred_f = model_pri.predict(X_valid)\n        pred_c = model2_pri.predict(X_valid2)\n        pred_c = (np.exp(pred_c)-1).clip(0, 1e10)\n        pred_f = (np.exp(pred_f)-1).clip(0, 1e10)\n        df_interest['fatal/day'][j+len_known] = pred_f\n        df_interest['cases/day'][j+len_known] = pred_c\n        df_interest['Fatalities'][j+len_known] = df_interest['Fatalities'][j+len_known-1] + pred_f\n        df_interest['ConfirmedCases'][j+len_known] = df_interest['ConfirmedCases'][j+len_known-1] + pred_c\n\n    if (i+1)%10==0:\n        print(\"{:3d}/{}  {}, len known: {}, len unknown: {}\".format(i+1, len(places), place, len_known, len_unknown), df_interest.shape)\n    df_interest['fatal_pred'] = np.cumsum(df_interest['fatal/day'].values)\n    df_interest['cases_pred'] = np.cumsum(df_interest['cases/day'].values)\n    df_preds_pri.append(df_interest)\ndf_preds_pri = pd.concat(df_preds_pri)","execution_count":396,"outputs":[{"output_type":"stream","text":" 10/313  Australia_New South Wales, len known: 106, len unknown: 8 (114, 63)\n 20/313  Bahrain_none, len known: 106, len unknown: 8 (114, 63)\n 30/313  Botswana_none, len known: 106, len unknown: 8 (114, 63)\n 40/313  Canada_Alberta, len known: 106, len unknown: 8 (114, 63)\n 50/313  Canada_Saskatchewan, len known: 106, len unknown: 8 (114, 63)\n 60/313  China_Guangdong, len known: 106, len unknown: 8 (114, 63)\n 70/313  China_Inner Mongolia, len known: 106, len unknown: 8 (114, 63)\n 80/313  China_Shanghai, len known: 106, len unknown: 8 (114, 63)\n 90/313  Congo (Kinshasa)_none, len known: 106, len unknown: 8 (114, 63)\n100/313  Diamond Princess_none, len known: 106, len unknown: 8 (114, 63)\n110/313  Eswatini_none, len known: 106, len unknown: 8 (114, 63)\n120/313  France_Reunion, len known: 106, len unknown: 8 (114, 63)\n130/313  Greece_none, len known: 106, len unknown: 8 (114, 63)\n140/313  Iceland_none, len known: 106, len unknown: 8 (114, 63)\n150/313  Jordan_none, len known: 106, len unknown: 8 (114, 63)\n160/313  Liberia_none, len known: 106, len unknown: 8 (114, 63)\n170/313  Mali_none, len known: 106, len unknown: 8 (114, 63)\n180/313  Mozambique_none, len known: 106, len unknown: 8 (114, 63)\n190/313  Niger_none, len known: 106, len unknown: 8 (114, 63)\n200/313  Philippines_none, len known: 106, len unknown: 8 (114, 63)\n210/313  San Marino_none, len known: 106, len unknown: 8 (114, 63)\n220/313  Somalia_none, len known: 106, len unknown: 8 (114, 63)\n230/313  Taiwan*_none, len known: 106, len unknown: 8 (114, 63)\n240/313  US_Arizona, len known: 106, len unknown: 8 (114, 63)\n250/313  US_Hawaii, len known: 106, len unknown: 8 (114, 63)\n260/313  US_Massachusetts, len known: 106, len unknown: 8 (114, 63)\n270/313  US_New Mexico, len known: 106, len unknown: 8 (114, 63)\n280/313  US_South Carolina, len known: 106, len unknown: 8 (114, 63)\n290/313  US_Wisconsin, len known: 106, len unknown: 8 (114, 63)\n300/313  United Kingdom_Falkland Islands (Malvinas), len known: 106, len unknown: 8 (114, 63)\n310/313  West Bank and Gaza_none, len known: 106, len unknown: 8 (114, 63)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"places_sort = df_traintest10[['place_id', 'ConfirmedCases']][df_traintest10['day']==day_before_private]\nplaces_sort = places_sort.sort_values('ConfirmedCases', ascending=False).reset_index(drop=True)['place_id'].values\nprint(len(places_sort))\nplaces_sort[:5]","execution_count":397,"outputs":[{"output_type":"stream","text":"313\n","name":"stdout"},{"output_type":"execute_result","execution_count":397,"data":{"text/plain":"array(['US_New York', 'Spain_none', 'Italy_none', 'United Kingdom_none',\n       'France_none'], dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Fatalities / Public\")\nplt.figure(figsize=(30,30))\nfor i in range(30):\n    plt.subplot(5,6,i+1)\n    idx = i * 10\n    df_interest = df_preds[df_preds['place_id']==places_sort[idx]].reset_index(drop=True)\n    tmp = df_interest['fatal/day'].values\n    tmp = np.cumsum(tmp)\n    sns.lineplot(x=df_interest['day'], y=tmp, label='pred')\n    df_interest2 = df_traintest10[(df_traintest10['place_id']==places_sort[idx]) & (df_traintest10['day']<=day_before_private)].reset_index(drop=True)\n    sns.lineplot(x=df_interest2['day'].values, y=df_interest2['Fatalities'].values, label='true')\n    plt.title(places_sort[idx])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Confirmed Cases / Public\")\nplt.figure(figsize=(30,30))\nfor i in range(30):\n    plt.subplot(5,6,i+1)\n    idx = i * 10\n    df_interest = df_preds[df_preds['place_id']==places_sort[idx]].reset_index(drop=True)\n    tmp = df_interest['cases/day'].values\n    tmp = np.cumsum(tmp)\n    sns.lineplot(x=df_interest['day'], y=tmp, label='pred')\n    df_interest2 = df_traintest10[(df_traintest10['place_id']==places_sort[idx]) & (df_traintest10['day']<=day_before_private)].reset_index(drop=True)\n    sns.lineplot(x=df_interest2['day'].values, y=df_interest2['ConfirmedCases'].values, label='true')\n    plt.title(places_sort[idx])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Fatalities / Private\")\nplt.figure(figsize=(30,30))\nfor i in range(30):\n    plt.subplot(5,6,i+1)\n    idx = i * 10\n    df_interest = df_preds_pri[df_preds_pri['place_id']==places_sort[idx]].reset_index(drop=True)\n    tmp = df_interest['fatal/day'].values\n    tmp = np.cumsum(tmp)\n    sns.lineplot(x=df_interest['day'], y=tmp, label='pred')\n    df_interest2 = df_traintest10[(df_traintest10['place_id']==places_sort[idx]) & (df_traintest10['day']<=day_before_private)].reset_index(drop=True)\n    sns.lineplot(x=df_interest2['day'].values, y=df_interest2['Fatalities'].values, label='true')\n    plt.title(places_sort[idx])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ConfirmedCases / Private\")\nplt.figure(figsize=(30,30))\nfor i in range(30):\n    plt.subplot(5,6,i+1)\n    idx = i * 10\n    df_interest = df_preds_pri[df_preds_pri['place_id']==places_sort[idx]].reset_index(drop=True)\n    tmp = df_interest['cases/day'].values\n    tmp = np.cumsum(tmp)\n    sns.lineplot(x=df_interest['day'], y=tmp, label='pred')\n    df_interest2 = df_traintest10[(df_traintest10['place_id']==places_sort[idx]) & (df_traintest10['day']<=day_before_private)].reset_index(drop=True)\n    sns.lineplot(x=df_interest2['day'].values, y=df_interest2['ConfirmedCases'].values, label='true')\n    plt.title(places_sort[idx])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# merge 2 preds\ndf_preds[df_preds['day']>day_before_private] = df_preds_pri[df_preds['day']>day_before_private]\n#df_preds[df_preds['day']>day_before_private] ","execution_count":365,"outputs":[{"output_type":"execute_result","execution_count":365,"data":{"text/plain":"     ConfirmedCases Country_Region       Date  Fatalities  ForecastId  Id  \\\n106     1942.777458    Afghanistan 2020-05-07   60.176042        36.0 NaN   \n107     1943.251483    Afghanistan 2020-05-08   60.198047        37.0 NaN   \n108     1943.725508    Afghanistan 2020-05-09   60.220052        38.0 NaN   \n109     1944.199533    Afghanistan 2020-05-10   60.242058        39.0 NaN   \n110     1944.673558    Afghanistan 2020-05-11   60.264063        40.0 NaN   \n..              ...            ...        ...         ...         ...  ..   \n109       35.847530       Zimbabwe 2020-05-10    4.242058     13455.0 NaN   \n110       36.219094       Zimbabwe 2020-05-11    4.264063     13456.0 NaN   \n111       36.590658       Zimbabwe 2020-05-12    4.286068     13457.0 NaN   \n112       36.978669       Zimbabwe 2020-05-13    4.308073     13458.0 NaN   \n113       37.365842       Zimbabwe 2020-05-14    4.330078     13459.0 NaN   \n\n     Lat  Long Province_State   age_0-4  ...  days_since_10cases  \\\n106  1.0   1.0           none  0.145717  ...                  54   \n107  1.0   1.0           none  0.145717  ...                  55   \n108  1.0   1.0           none  0.145717  ...                  56   \n109  1.0   1.0           none  0.145717  ...                  57   \n110  1.0   1.0           none  0.145717  ...                  58   \n..   ...   ...            ...       ...  ...                 ...   \n109  0.0   0.0           none       NaN  ...                  34   \n110  0.0   0.0           none       NaN  ...                  35   \n111  0.0   0.0           none       NaN  ...                  36   \n112  0.0   0.0           none       NaN  ...                  37   \n113  0.0   0.0           none       NaN  ...                  38   \n\n     days_since_100cases  days_since_1fatal  days_since_10fatal  \\\n106                   41                 46                  31   \n107                   42                 47                  32   \n108                   43                 48                  33   \n109                   44                 49                  34   \n110                   45                 50                  35   \n..                   ...                ...                 ...   \n109                    3                 48                   3   \n110                    4                 49                   4   \n111                    5                 50                   5   \n112                    6                 51                   6   \n113                    7                 52                   7   \n\n     days_since_100fatal     id  Country_Region_le  Province_State_le  \\\n106                    1    141                168                  0   \n107                    2    142                168                  0   \n108                    3    143                168                  0   \n109                    4    144                168                  0   \n110                    5    145                168                  0   \n..                   ...    ...                ...                ...   \n109                    3  46632                 79                  0   \n110                    4  46633                 79                  0   \n111                    5  46634                 79                  0   \n112                    6  46635                 79                  0   \n113                    7  46636                 79                  0   \n\n     fatal_pred   cases_pred  \n106   60.176042  1942.777458  \n107   60.198047  1943.251483  \n108   60.220052  1943.725508  \n109   60.242058  1944.199533  \n110   60.264063  1944.673558  \n..          ...          ...  \n109    4.242058    35.847530  \n110    4.264063    36.219094  \n111    4.286068    36.590658  \n112    4.308073    36.978669  \n113    4.330078    37.365842  \n\n[2504 rows x 65 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ConfirmedCases</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>Fatalities</th>\n      <th>ForecastId</th>\n      <th>Id</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Province_State</th>\n      <th>age_0-4</th>\n      <th>...</th>\n      <th>days_since_10cases</th>\n      <th>days_since_100cases</th>\n      <th>days_since_1fatal</th>\n      <th>days_since_10fatal</th>\n      <th>days_since_100fatal</th>\n      <th>id</th>\n      <th>Country_Region_le</th>\n      <th>Province_State_le</th>\n      <th>fatal_pred</th>\n      <th>cases_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>106</th>\n      <td>1942.777458</td>\n      <td>Afghanistan</td>\n      <td>2020-05-07</td>\n      <td>60.176042</td>\n      <td>36.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>54</td>\n      <td>41</td>\n      <td>46</td>\n      <td>31</td>\n      <td>1</td>\n      <td>141</td>\n      <td>168</td>\n      <td>0</td>\n      <td>60.176042</td>\n      <td>1942.777458</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>1943.251483</td>\n      <td>Afghanistan</td>\n      <td>2020-05-08</td>\n      <td>60.198047</td>\n      <td>37.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>55</td>\n      <td>42</td>\n      <td>47</td>\n      <td>32</td>\n      <td>2</td>\n      <td>142</td>\n      <td>168</td>\n      <td>0</td>\n      <td>60.198047</td>\n      <td>1943.251483</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>1943.725508</td>\n      <td>Afghanistan</td>\n      <td>2020-05-09</td>\n      <td>60.220052</td>\n      <td>38.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>56</td>\n      <td>43</td>\n      <td>48</td>\n      <td>33</td>\n      <td>3</td>\n      <td>143</td>\n      <td>168</td>\n      <td>0</td>\n      <td>60.220052</td>\n      <td>1943.725508</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>1944.199533</td>\n      <td>Afghanistan</td>\n      <td>2020-05-10</td>\n      <td>60.242058</td>\n      <td>39.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>57</td>\n      <td>44</td>\n      <td>49</td>\n      <td>34</td>\n      <td>4</td>\n      <td>144</td>\n      <td>168</td>\n      <td>0</td>\n      <td>60.242058</td>\n      <td>1944.199533</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>1944.673558</td>\n      <td>Afghanistan</td>\n      <td>2020-05-11</td>\n      <td>60.264063</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>0.145717</td>\n      <td>...</td>\n      <td>58</td>\n      <td>45</td>\n      <td>50</td>\n      <td>35</td>\n      <td>5</td>\n      <td>145</td>\n      <td>168</td>\n      <td>0</td>\n      <td>60.264063</td>\n      <td>1944.673558</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>35.847530</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-10</td>\n      <td>4.242058</td>\n      <td>13455.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>34</td>\n      <td>3</td>\n      <td>48</td>\n      <td>3</td>\n      <td>3</td>\n      <td>46632</td>\n      <td>79</td>\n      <td>0</td>\n      <td>4.242058</td>\n      <td>35.847530</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>36.219094</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-11</td>\n      <td>4.264063</td>\n      <td>13456.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>35</td>\n      <td>4</td>\n      <td>49</td>\n      <td>4</td>\n      <td>4</td>\n      <td>46633</td>\n      <td>79</td>\n      <td>0</td>\n      <td>4.264063</td>\n      <td>36.219094</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>36.590658</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-12</td>\n      <td>4.286068</td>\n      <td>13457.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>36</td>\n      <td>5</td>\n      <td>50</td>\n      <td>5</td>\n      <td>5</td>\n      <td>46634</td>\n      <td>79</td>\n      <td>0</td>\n      <td>4.286068</td>\n      <td>36.590658</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>36.978669</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-13</td>\n      <td>4.308073</td>\n      <td>13458.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>37</td>\n      <td>6</td>\n      <td>51</td>\n      <td>6</td>\n      <td>6</td>\n      <td>46635</td>\n      <td>79</td>\n      <td>0</td>\n      <td>4.308073</td>\n      <td>36.978669</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>37.365842</td>\n      <td>Zimbabwe</td>\n      <td>2020-05-14</td>\n      <td>4.330078</td>\n      <td>13459.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>38</td>\n      <td>7</td>\n      <td>52</td>\n      <td>7</td>\n      <td>7</td>\n      <td>46636</td>\n      <td>79</td>\n      <td>0</td>\n      <td>4.330078</td>\n      <td>37.365842</td>\n    </tr>\n  </tbody>\n</table>\n<p>2504 rows  65 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preds.to_csv(\"df_preds.csv\", index=None)","execution_count":366,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_sub = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\nprint(len(df_sub))\ndf_sub.head()","execution_count":367,"outputs":[{"output_type":"stream","text":"13459\n","name":"stdout"},{"output_type":"execute_result","execution_count":367,"data":{"text/plain":"   ForecastId  ConfirmedCases  Fatalities\n0           1               1           1\n1           2               1           1\n2           3               1           1\n3           4               1           1\n4           5               1           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ForecastId</th>\n      <th>ConfirmedCases</th>\n      <th>Fatalities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_sub = pd.merge(df_sub, df_traintest[['ForecastId', 'place_id', 'day']])\ndf_sub = pd.merge(df_sub, df_preds[['place_id', 'day', 'cases_pred', 'fatal_pred']], on=['place_id', 'day',], how='left')\ndf_sub.head(10)","execution_count":368,"outputs":[{"output_type":"execute_result","execution_count":368,"data":{"text/plain":"   ForecastId  ConfirmedCases  Fatalities          place_id  day  cases_pred  \\\n0           1               1           1  Afghanistan_none   93       273.0   \n1           2               1           1  Afghanistan_none   94       281.0   \n2           3               1           1  Afghanistan_none   95       299.0   \n3           4               1           1  Afghanistan_none   96       349.0   \n4           5               1           1  Afghanistan_none   97       367.0   \n5           6               1           1  Afghanistan_none   98       423.0   \n6           7               1           1  Afghanistan_none   99       444.0   \n7           8               1           1  Afghanistan_none  100       484.0   \n8           9               1           1  Afghanistan_none  101       521.0   \n9          10               1           1  Afghanistan_none  102       555.0   \n\n   fatal_pred  \n0         6.0  \n1         6.0  \n2         7.0  \n3         7.0  \n4        11.0  \n5        14.0  \n6        14.0  \n7        15.0  \n8        15.0  \n9        18.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ForecastId</th>\n      <th>ConfirmedCases</th>\n      <th>Fatalities</th>\n      <th>place_id</th>\n      <th>day</th>\n      <th>cases_pred</th>\n      <th>fatal_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>93</td>\n      <td>273.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>94</td>\n      <td>281.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>95</td>\n      <td>299.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>96</td>\n      <td>349.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>97</td>\n      <td>367.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>98</td>\n      <td>423.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>99</td>\n      <td>444.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>100</td>\n      <td>484.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>101</td>\n      <td>521.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Afghanistan_none</td>\n      <td>102</td>\n      <td>555.0</td>\n      <td>18.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub['ConfirmedCases'] = df_sub['cases_pred']\ndf_sub['Fatalities'] = df_sub['fatal_pred']\ndf_sub = df_sub[['ForecastId', 'ConfirmedCases', 'Fatalities']]\ndf_sub.to_csv(\"submission.csv\", index=None)\ndf_sub.head(10)","execution_count":369,"outputs":[{"output_type":"execute_result","execution_count":369,"data":{"text/plain":"   ForecastId  ConfirmedCases  Fatalities\n0           1           273.0         6.0\n1           2           281.0         6.0\n2           3           299.0         7.0\n3           4           349.0         7.0\n4           5           367.0        11.0\n5           6           423.0        14.0\n6           7           444.0        14.0\n7           8           484.0        15.0\n8           9           521.0        15.0\n9          10           555.0        18.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ForecastId</th>\n      <th>ConfirmedCases</th>\n      <th>Fatalities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>273.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>281.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>299.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>349.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>367.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>423.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>444.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>484.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>521.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>555.0</td>\n      <td>18.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureslist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def func(x):\n    try:\n        x_new = x['Country_Region'] + \"_\" + x['Province_State']\n    except:\n        x_new = x['Country_Region']\n    return x_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/submission.csv\")\n\ntrain_df['ConfirmedCases']=train_df['ConfirmedCases'].replace([-1], 0)\ntrain_df['Fatalities']=train_df['Fatalities'].replace([-1], 0)\ntrain_df['key'] = train_df.apply(lambda x: func(x), axis=1)\n#train_df[\"key\"]=train_df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"\" + str(row[1]),axis=1)\n\n#train_df['cases_prev']=train_df.groupby(\"key\")[\"ConfirmedCases\"].shift()\n#train_df['fat_prev']=train_df.groupby(\"key\")[\"Fatalities\"].shift()\n\ntrain_df['cases_prev'] = train_df.groupby(\"key\")[\"ConfirmedCases\"].shift()\ntrain_df['fat_prev'] = train_df.groupby(\"key\")[\"Fatalities\"].shift()\n\nsub_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\n\n#sub_df[\"key\"]=sub_df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"\" + str(row[1]),axis=1)\nsub_df['key'] = sub_df.apply(lambda x: func(x), axis=1)\ncoo_d = merged_train_df.groupby('key')[['mean_rate_case_last7', 'mean_rate_case_each7',\n       'mean_rate_fat_last7', 'mean_rate_fat_each7', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case','mean_rate_case_last3','mean_rate_fat_last3',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat','Lat','Long',\n       'max_to_min_rate_fat', 'rate_ConfirmedCases', 'rate_Fatalities','total_pop', 'smokers_perc', 'density']].mean().reset_index()\nloc_group = ['key']\ndef preprocess(df):\n        df[\"Date\"] = df[\"Date\"].astype(\"datetime64[ms]\")\n     #   df[\"days\"] = (df[\"Date\"] - pd.to_datetime(\"2020-01-01\")).dt.days\n    #    df[\"weekend\"] = df[\"Date\"].dt.dayofweek//5\n\n        df = df.merge(coo_d, how=\"left\", on='key')\n        df[\"Lat\"] = (df[\"Lat\"] // 30).astype(np.float32).fillna(0)\n        df[\"Long\"] = (df[\"Long\"] // 60).astype(np.float32).fillna(0)\n        key_dummies = pd.get_dummies(df['key'])\n        df = pd.concat([df,key_dummies],axis=1)\n        for col in loc_group:\n            df[col].fillna(\"none\", inplace=True)\n        return df\n\n\n#x_train = merged_train_df2\nsub_df=preprocess(sub_df)\nx_train = preprocess(train_df)\nx_test = sub_df\nx_train.loc[x_train[\"Date\"]<x_test['Date'].min(),\"split\"] = \"train\"\nx_train.loc[x_train[\"Date\"]>=x_test['Date'].min(),\"split\"] = \"test\"       \n\nfeatureslist=x_train.columns.unique().tolist()\nfeatures=['mean_rate_case_last7',\n 'mean_rate_case_each7',\n 'mean_rate_fat_last7',\n 'mean_rate_fat_each7',\n 'max_rate_case',\n 'min_rate_case',\n 'std_rate_case',\n 'mode_rate_case',\n 'range_rate_case',\n 'mean_rate_case_last3',\n 'mean_rate_fat_last3',\n 'max_to_min_rate_case',\n 'max_rate_fat',\n 'min_rate_fat',\n 'std_rate_fat',\n 'mode_rate_fat',\n 'mean_rate_case',\n 'mean_rate_fat',\n 'range_rate_fat',\n 'Lat',\n 'Long',\n 'max_to_min_rate_fat',\n 'rate_ConfirmedCases',\n 'rate_Fatalities',\n 'total_pop',\n 'smokers_perc',\n 'density',\n ]\ndef train_model(df, label, base_label, features=features, **kwargs):\n    X_train = df.loc[df[\"split\"] == \"train\"][features]\n    y_train = np.log(df.loc[df[\"split\"] == \"train\"][label] + 1)\n    b_train = np.log(df.loc[df[\"split\"] == \"train\"][base_label] + 1)\n    X_test = df.loc[df[\"split\"] == \"test\"][features]\n    y_test = np.log(df.loc[df[\"split\"] == \"test\", label] + 1)\n    b_test = np.log(df.loc[df[\"split\"] == \"test\", base_label] + 1)\n    print(kwargs)\n    model = lgb.LGBMRegressor(**kwargs)\n    model.fit(X_train, y_train, init_score = b_train)\n    y_pred = model.predict(X_test)\n    print(np.sqrt(mean_squared_error(y_test, y_pred + b_test)))\n   # print(len(X_test))\n    return model\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model_cases = train_model(x_train,\"ConfirmedCases\",'cases_prev',features,\n                                   max_depth=5,\n                                   colsample_bytree=0.8,\n                                   learning_rate=0.1,\n                                   n_estimators=1000,\n                                   subsample=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# sorted(zip(clf.feature_importances_, X.columns), reverse=True)\nfeature_imp = pd.DataFrame(sorted(zip(lgb_model_cases.feature_importances_,x_train[features])), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances-01.png')\n\n\n\nlgb_model_fatalities = train_model(x_train, \"Fatalities\",'fat_prev',features, \n                                   max_depth=5,\n                                   colsample_bytree=0.8,\n                                   learning_rate=0.1,\n                                   n_estimators=500,\n                                   subsample=0.8\n                                  )\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# sorted(zip(clf.feature_importances_, X.columns), reverse=True)\nfeature_imp = pd.DataFrame(sorted(zip(lgb_model_fatalities.feature_importances_,x_train[features])), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances-01.png')\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = x_train[features]\ny_train = np.log(x_train[\"ConfirmedCases\"] + 1)\nb_train = np.log(x_train[\"cases_prev\"] + 1)\ncases_model = lgb.LGBMRegressor(max_depth=5,\n                                   colsample_bytree=0.8,\n                                   learning_rate=0.1,\n                                   n_estimators=500,\n                                   subsample=0.8\n                               )\ncases_model.fit(X_train, y_train, init_score = b_train)\n\nX_train = x_train[features]\ny_train = np.log(x_train[\"Fatalities\"] + 1)\nb_train = np.log(x_train[\"fat_prev\"] + 1)\nfatalities_model = lgb.LGBMRegressor(max_depth=5,\n                                   colsample_bytree=0.8,\n                                   learning_rate=0.1,\n                                   n_estimators=500,\n                                   subsample=0.8)\nfatalities_model.fit(X_train, y_train, init_score = b_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndf = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\nsub_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\ndf[\"key\"]=train_df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\nsub_df[\"key\"]=sub_df[[\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\n\n\ncoo_df = merged_train_df.groupby(\"key\")[['mean_rate_case_last7', 'mean_rate_case_each7',\n       'mean_rate_fat_last7', 'mean_rate_fat_each7', 'max_rate_case',\n       'min_rate_case', 'std_rate_case', 'mode_rate_case', 'range_rate_case',\n       'max_to_min_rate_case', 'max_rate_fat', 'min_rate_fat', 'std_rate_fat','mean_rate_case_last3','mean_rate_fat_last3',\n       'mode_rate_fat', 'mean_rate_case', 'mean_rate_fat', 'range_rate_fat','Lat','Long',\n       'max_to_min_rate_fat', 'rate_ConfirmedCases', 'rate_Fatalities','total_pop', 'smokers_perc', 'density']].mean().reset_index()\n   # coo_df = coo_df[coo_df[\"Country_Region\"].notnull()]\n\nloc_group = [\"key\"]\n   # merged_train_df['Date']= pd.to_datetime(merged_train_df['Date']) \n  #  merged_train_df[\"days\"] = (merged_train_df[\"Date\"] - pd.to_datetime(\"2020-01-01\")).dt.days\nkey_list=df['key'].unique()\ndef preprocess(df):\n    df[\"Date\"] = df[\"Date\"].astype(\"datetime64[ms]\")\n  #  df[\"days\"] = (df[\"Date\"] - pd.to_datetime(\"2020-01-01\")).dt.days\n    #    df[\"weekend\"] = df[\"Date\"].dt.dayofweek//5\n\n    df = df.merge(coo_df, how=\"left\", on=\"key\")\n    df[\"Lat\"] = (df[\"Lat\"] // 30).astype(np.float32).fillna(0)\n    df[\"Long\"] = (df[\"Long\"] // 60).astype(np.float32).fillna(0)\n    key_dummies = pd.get_dummies(df['key'])\n    df = pd.concat([df,key_dummies],axis=1)\n\n    for col in loc_group:\n        df[col].fillna(\"none\", inplace=True)\n    return df\n\ndf = preprocess(df)\nsub_df = preprocess(sub_df)\n\n\n#train_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\n#test_df = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\n\n#train_df['Date']= pd.to_datetime(train_df['Date']) \ncountry_list = train_df ['Country_Region'].unique()\nkey_list=df['key'].unique()\n#train_df['Date']= pd.to_datetime(train_df['Date']) \n\n\nscoring_dates = test_df['Date'].unique()\npred_df = pd.DataFrame(columns=train_df.columns)\n\nsub = []\nfor date in scoring_dates.tolist():\n    print(date)\n    start=time.time()\n    \n    if date < train_df['Date'].max():\n            \n        new_df = df.loc[df[\"Date\"] < date].copy()\n        curr_date_df = sub_df.loc[sub_df[\"Date\"] == date].copy()\n        curr_date_df[\"ConfirmedCases\"] = 0\n        curr_date_df[\"Fatalities\"] = 0\n        new_df = new_df.append(curr_date_df).reset_index(drop=True)\n        new_df['cases_prev']=new_df.groupby(\"key\")[\"ConfirmedCases\"].shift()\n        new_df['fat_prev']=new_df.groupby(\"key\")[\"Fatalities\"].shift()\n        \n        \n    \n\n        predictions = cases_model.predict(new_df[features]) + np.log(new_df[\"cases_prev\"] + 1)\n        new_df[\"predicted_cases\"] = round(np.maximum(np.exp(predictions) - 1, new_df[\"cases_prev\"]))\n        predictions = fatalities_model.predict(new_df[features]) + np.log(new_df[\"fat_prev\"] + 1)\n        new_df[\"predicted_fatalities\"] = np.maximum(np.exp(predictions) - 1, new_df[\"fat_prev\"])\n        new_df[\"predicted_fatalities\"] = round(np.minimum(new_df[\"predicted_fatalities\"], new_df[\"predicted_cases\"]*0.2))\n        new_df.loc[new_df[\"Date\"] == date, \"ConfirmedCases\"] = new_df.loc[new_df[\"Date\"] == date, \"predicted_cases\"]\n        new_df.loc[new_df[\"Date\"] == date, \"Fatalities\"] = new_df.loc[new_df[\"Date\"] == date, \"predicted_fatalities\"]\n        pred_df = pred_df.append(new_df.loc[new_df[\"Date\"] == date][pred_df.columns.tolist()])\n            \n        \n       \n    else:\n            #new_df = new_df.copy()\n        curr_date_df = sub_df.loc[sub_df[\"Date\"] == date].copy()\n        curr_date_df[\"ConfirmedCases\"] = 0\n        curr_date_df[\"Fatalities\"] = 0\n        new_df = new_df.append(curr_date_df).reset_index(drop=True)\n        new_df['cases_prev']=new_df.groupby(\"key\")[\"ConfirmedCases\"].shift()\n        new_df['fat_prev']=new_df.groupby(\"key\")[\"Fatalities\"].shift()\n        \n        predictions = cases_model.predict(new_df[features]) + np.log(new_df[\"cases_prev\"] + 1)\n        new_df[\"predicted_cases\"] = round(np.maximum(np.exp(predictions) - 1, new_df[\"cases_prev\"]))\n        predictions = fatalities_model.predict(new_df[features]) + np.log(new_df[\"fat_prev\"] + 1)\n        new_df[\"predicted_fatalities\"] = np.maximum(np.exp(predictions) - 1, new_df[\"fat_prev\"])\n        new_df[\"predicted_fatalities\"] = round(np.minimum(new_df[\"predicted_fatalities\"], new_df[\"predicted_cases\"]*0.2))\n        new_df.loc[new_df[\"Date\"] == date, \"ConfirmedCases\"] = new_df.loc[new_df[\"Date\"] == date, \"predicted_cases\"]\n        new_df.loc[new_df[\"Date\"] == date, \"Fatalities\"] = new_df.loc[new_df[\"Date\"] == date, \"predicted_fatalities\"]\n        pred_df = pred_df.append(new_df.loc[new_df[\"Date\"] == date][pred_df.columns.tolist()])\n            \n    print(time.time()-start)  \nfor key in key_list:\n    \n    X_forecastId = sub_df.loc[(sub_df['key'] == key), ['ForecastId']]\n    X_forecastId = X_forecastId.values.tolist()\nX_forecastId = [v[0] for v in X_forecastId]\nfor j in range(len(sub_df['ForecastId'])):\n          \n    dic = { 'ForecastId': sub_df['ForecastId'][j], 'ConfirmedCases': pred_df['ConfirmedCases'][j], 'Fatalities': pred_df['Fatalities'][j]}\n    sub.append(dic)\n\nsubmission = pd.DataFrame(sub)\nsubmission[['ForecastId','ConfirmedCases','Fatalities']].to_csv(path_or_buf='submission.csv',index=False) \nfrom Gaussiandistribution import Gaussian","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(pred_df['ConfirmedCases']),len(sub_df['ForecastId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range(len(sub_df['ForecastId']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_forecastId)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(key_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df[pred_df['Country_Region']=='Qatar']","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}